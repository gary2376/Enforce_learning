
# 🎰 HW3 專題: Multi-Armed Bandit Algorithms Comprehensive Analysis

### GPT問答紀錄：https://chatgpt.com/share/67f68e6a-0934-8010-adfe-ae75f35fd5e5

---

## 1. 演算法介紹（含公式、邏輯、程式碼、結果）

（保留原始 Epsilon-Greedy、UCB、Softmax、Thompson Sampling 四大區塊，包括 LaTeX公式、程式碼與圖表、結果解釋）

---

## 2. 結果深入分析

### 2.1 空間與時間面向分析

- **空間角度**：所有演算法所需空間複雜度均為 O(k)，即與行動數 k 成正比，非常輕量，適合大規模應用。
- **時間角度**：
  - **Epsilon-Greedy**：中速收斂，epsilon 影響探索程度，探索不足易陷入局部最優。
  - **UCB**：快速收斂，自動強化早期探索，後期專注於高回報臂。
  - **Softmax**：依溫度參數調節收斂，適中或緩慢，適合回報值接近時穩定收斂。
  - **Thompson Sampling**：平滑且穩定的收斂曲線，通常能取得最佳的長期回報。

### 2.2 各演算法優勢與限制比較

- **Epsilon-Greedy**：
  - 優勢：簡單易懂、好實作。
  - 限制：固定探索率，不適應學習進度變化。

- **UCB**：
  - 優勢：自動調節探索強度，理論有保障。
  - 限制：對超參數 c 敏感。

- **Softmax**：
  - 優勢：機率性柔和控制，避免過度硬切換。
  - 限制：溫度參數 τ 設定困難，過大或過小皆有問題。

- **Thompson Sampling**：
  - 優勢：自然融合探索與利用、表現穩定。
  - 限制：需選對 prior 分布，非二元回報時較複雜。

### 2.3 不同情境下的表現差異

| 情境              | 推薦演算法                | 分析說明                                                  |
|------------------|-------------------------|--------------------------------------------------------|
| 不明顯最優選項         | UCB、Thompson Sampling  | 初期需大量探索以識別最佳行動。                                     |
| 最優臂明顯             | Epsilon-Greedy、UCB    | 可快速專注於最優臂，加速收斂。                                   |
| 多臂回報接近           | Softmax、Thompson Sampling | 適合用平滑方式選擇，不容易陷入單一路徑。                               |
| 有時間限制           | UCB、Thompson Sampling  | 快速辨識高回報行動，早期就能取得好成績。                              |

---

## 3. 總整理與選擇指南

- **新手或快速部署**：建議使用 **Epsilon-Greedy**。
- **期望穩定高回報**：建議使用 **Thompson Sampling**。
- **想強化探索與理論保證**：建議使用 **UCB**。
- **希望機率式平滑切換**：建議使用 **Softmax**。

---

## 4. 統整總表

| 演算法               | 探索機制             | 是否機率性 | 主要參數        | 收斂速度 | 優點                                             | 缺點                                           |
|--------------------|--------------------|--------|------------|------|-----------------------------------------------|----------------------------------------------|
| Epsilon-Greedy     | 隨機探索             | 否      | $\epsilon$  | 中   | 簡單易懂，容易上手                                   | 探索率固定，不自適應                                 |
| UCB                | 樂觀初始原則探索       | 否      | c          | 快   | 自動探索，收斂快                                   | 超參數敏感，需調整                                 |
| Softmax            | 機率性依據價值選擇      | 是      | $	au$      | 中   | 探索平滑，避免硬切換                                  | 對溫度參數敏感                                   |
| Thompson Sampling  | 基於後驗分布取樣探索    | 是      | prior 分布  | 快   | 平衡探索與利用，自然調整                                 | 適用範圍需考量，非Bernoulli需改設計                          |

---

# ✅ 本報告完畢！
