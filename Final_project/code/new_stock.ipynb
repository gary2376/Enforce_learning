{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 讀檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_all_stock_data(folder_path):\n",
    "    all_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            tic = filename.replace(\"converted_\", \"\").replace(\".csv\", \"\")\n",
    "            df = pd.read_csv(path)\n",
    "            df['tic'] = tic  # 加上股票代碼欄位\n",
    "            all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 📂 資料夾路徑\n",
    "folder_path = \"E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\converted_stock\"\n",
    "\n",
    "# 📈 載入所有股票資料\n",
    "raw_df = load_all_stock_data(folder_path)\n",
    "\n",
    "# # 🔍 查看資料概況\n",
    "# print(raw_df.shape)\n",
    "# print(raw_df[['date', 'tic']].drop_duplicates().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 補值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12610, 7)\n",
      "        date       open       high        low      close     volume      tic\n",
      "0 2020-01-01  82.237405  83.042405  82.237405  82.745827  4882015.0  0050.TW\n",
      "1 2020-01-02  82.237405  83.042405  82.237405  82.745827  4882015.0  0050.TW\n",
      "2 2020-01-03  83.296619  83.635563  82.195034  82.745827  6813547.0  0050.TW\n",
      "3 2020-01-06  82.237408  82.279772  81.686615  81.686615  9321768.0  0050.TW\n",
      "4 2020-01-07  81.728982  81.940825  80.839246  81.432404  6328602.0  0050.TW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def interpolate_stock_data(df, start_date=\"2020-01-01\", end_date=\"2024-10-30\"):\n",
    "    # 建立完整日期範圍（僅工作日）\n",
    "    full_dates = pd.date_range(start=start_date, end=end_date, freq='B')  # 'B' 是 business day\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for tic in df['tic'].unique():\n",
    "        sub_df = df[df['tic'] == tic].copy()\n",
    "        sub_df['date'] = pd.to_datetime(sub_df['date'])\n",
    "\n",
    "        # 設定 index 為日期後 reindex\n",
    "        sub_df = sub_df.set_index('date').reindex(full_dates)\n",
    "        sub_df['tic'] = tic  # 保留股票代碼欄位\n",
    "        sub_df.index.name = 'date'\n",
    "\n",
    "        # 線性補值（針對數值欄位）\n",
    "        num_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "        for col in num_cols:\n",
    "            if col in sub_df.columns:\n",
    "                sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "        result_list.append(sub_df.reset_index())\n",
    "\n",
    "    # 合併所有股票資料\n",
    "    full_df = pd.concat(result_list, ignore_index=True)\n",
    "    return full_df\n",
    "\n",
    "# 📈 執行補值\n",
    "interpolated_df = interpolate_stock_data(raw_df)\n",
    "\n",
    "# 🔍 檢查結果\n",
    "print(interpolated_df.shape)\n",
    "print(interpolated_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DTW分群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tslearn.metrics import cdist_dtw\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_return(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    result = {}\n",
    "\n",
    "    for tic in df['tic'].unique():\n",
    "        sub_df = df[df['tic'] == tic].copy().set_index('date').sort_index()\n",
    "        sub_df['log_return'] = np.log(sub_df['close'] / sub_df['close'].shift(1))\n",
    "        result[tic] = sub_df['log_return'].dropna()\n",
    "\n",
    "    return pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_return(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    result = {}\n",
    "\n",
    "    for tic in df['tic'].unique():\n",
    "        sub_df = df[df['tic'] == tic].copy().set_index('date').sort_index()\n",
    "        sub_df['log_return'] = np.log(sub_df['close'] / sub_df['close'].shift(1))\n",
    "        result[tic] = sub_df['log_return'].dropna()\n",
    "\n",
    "    return pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dtw_cluster(log_return_df, k=3):\n",
    "    series_array = log_return_df.T.values[..., np.newaxis]\n",
    "    dist_matrix = cdist_dtw(series_array)\n",
    "    initial_medoids = list(range(k))\n",
    "\n",
    "    kmedoids_instance = kmedoids(dist_matrix, initial_medoids, data_type='distance_matrix', ccore=False)\n",
    "    kmedoids_instance.process()\n",
    "    clusters = kmedoids_instance.get_clusters()\n",
    "\n",
    "    label_map = {}\n",
    "    stock_list = list(log_return_df.columns)\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        for idx in cluster:\n",
    "            label_map[stock_list[idx]] = i\n",
    "    return label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(log_return_df, cluster_labels):\n",
    "    grouped_stocks = {}\n",
    "    for stock, group in cluster_labels.items():\n",
    "        grouped_stocks.setdefault(group, []).append(stock)\n",
    "\n",
    "    for group_id, stocks in grouped_stocks.items():\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        for stock in stocks:\n",
    "            plt.plot(log_return_df.index, log_return_df[stock], label=stock)\n",
    "        plt.title(f\"group {group_id}:no.{len(stocks)} \")\n",
    "        plt.xlabel(\"date\")\n",
    "        plt.ylabel(\"normalization Log Return\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\1499623503.py:23: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sub_df[col] = sub_df[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\2241493175.py:16: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料夾中所有股票 CSV\n",
    "def load_all_stock_data(folder_path):\n",
    "    all_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            tic = filename.replace(\"converted_\", \"\").replace(\".csv\", \"\")\n",
    "            df = pd.read_csv(path)\n",
    "            df['tic'] = tic\n",
    "            all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# 讀取 + 補值\n",
    "folder_path = \"E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\converted_stock\"\n",
    "raw_df = load_all_stock_data(folder_path)\n",
    "interpolated_df = interpolate_stock_data(raw_df)\n",
    "\n",
    "# 計算 log return 並切割訓練集（只用到 2023-12-31）\n",
    "log_return_df = calculate_log_return(interpolated_df)\n",
    "train_log_return_df = log_return_df[log_return_df.index <= '2023-12-31']\n",
    "\n",
    "# 正規化並分群\n",
    "cluster_labels = dtw_cluster(train_log_return_df, k=6)\n",
    "\n",
    "# 畫出分群結果\n",
    "plot_clusters(train_log_return_df, cluster_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3 import PPO\n",
    "from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "class CustomStockTradingEnv(gym.Env):\n",
    "    def __init__(self, config):\n",
    "        super(CustomStockTradingEnv, self).__init__()\n",
    "\n",
    "        self.price_array = config['price_array']\n",
    "        self.tech_array = config['tech_array']\n",
    "        self.turbulence_array = config['turbulence_array']\n",
    "        self.initial_amount = config.get('initial_amount', 1e6)\n",
    "        self.buy_cost_pct = config.get('buy_cost_pct', 0.001)\n",
    "        self.sell_cost_pct = config.get('sell_cost_pct', 0.001)\n",
    "        self.reward_scaling = config.get('reward_scaling', 1e-4)\n",
    "        self.if_train = config.get('if_train', True)\n",
    "        self.max_stock = config.get('max_stock', 1e4)\n",
    "        self.min_trade_unit = config.get('min_trade_unit', 1)\n",
    "\n",
    "        self.day = 0\n",
    "        self.data_length, self.stock_dim = self.price_array.shape\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(self.stock_dim,), dtype=np.float32)\n",
    "        obs_dim = 1 + self.stock_dim + self.price_array.shape[1] + self.tech_array.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.day = 0\n",
    "        self.amount = self.initial_amount\n",
    "        self.stocks = np.zeros(self.stock_dim, dtype=np.float32)\n",
    "        self.total_asset = self.amount\n",
    "        self.asset_memory = [self.total_asset]\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, actions):\n",
    "        actions = actions * self.max_stock\n",
    "        actions = np.round(actions / self.min_trade_unit) * self.min_trade_unit\n",
    "\n",
    "        begin_total_asset = self._calculate_total_asset()\n",
    "        prices = self.price_array[self.day]\n",
    "\n",
    "        # 停損邏輯（賣出前一天跌超過 10%）\n",
    "        if self.day > 0:\n",
    "            prev_prices = self.price_array[self.day - 1]\n",
    "            price_change = (prices - prev_prices) / prev_prices\n",
    "            for i in range(self.stock_dim):\n",
    "                if price_change[i] < -0.10 and self.stocks[i] > 0:\n",
    "                    # 強制停損\n",
    "                    slippage = np.random.normal(0, 0.005) if self.if_train else 0.0\n",
    "                    traded_price = prices[i] * (1 + slippage)\n",
    "                    proceeds = self.stocks[i] * traded_price * (1 - self.sell_cost_pct)\n",
    "                    self.amount += proceeds\n",
    "                    self.stocks[i] = 0\n",
    "\n",
    "        for i in range(self.stock_dim):\n",
    "            action = actions[i]\n",
    "            price = prices[i]\n",
    "            if np.isnan(price) or price < 1e-6:\n",
    "                continue\n",
    "\n",
    "            slippage = np.random.normal(0, 0.005) if self.if_train else 0.0\n",
    "            traded_price = price * (1 + slippage)\n",
    "\n",
    "            # Buy\n",
    "            if action > 0:\n",
    "                max_buyable = min(\n",
    "                    (self.amount // (traded_price * (1 + self.buy_cost_pct))),\n",
    "                    self.max_stock - self.stocks[i]\n",
    "                )\n",
    "                trade_amount = min(action, max_buyable)\n",
    "                cost = trade_amount * traded_price * (1 + self.buy_cost_pct)\n",
    "                self.amount -= cost\n",
    "                self.stocks[i] += trade_amount\n",
    "\n",
    "            # Sell\n",
    "            elif action < 0:\n",
    "                trade_amount = min(-action, self.stocks[i])\n",
    "                proceeds = trade_amount * traded_price * (1 - self.sell_cost_pct)\n",
    "                self.amount += proceeds\n",
    "                self.stocks[i] -= trade_amount\n",
    "\n",
    "        self.day += 1\n",
    "        done = self.day >= self.data_length - 1\n",
    "\n",
    "        end_total_asset = self._calculate_total_asset()\n",
    "        reward = (end_total_asset - begin_total_asset) * self.reward_scaling\n",
    "        self.total_asset = end_total_asset\n",
    "        self.asset_memory.append(self.total_asset)\n",
    "\n",
    "        # ✅ 每日資產增幅過大時，強制 done\n",
    "        daily_return = (end_total_asset - begin_total_asset) / begin_total_asset\n",
    "        if daily_return > 1.0:  # 超過 +100%\n",
    "            print(\"⚠️ Daily return too high, forcing stop.\")\n",
    "            done = True\n",
    "\n",
    "        # ✅ 最大回撤限制（-30%）\n",
    "        peak = max(self.asset_memory[:-1]) if len(self.asset_memory) > 1 else self.initial_amount\n",
    "        drawdown = (end_total_asset - peak) / peak\n",
    "        if drawdown < -0.3:\n",
    "            print(\"⚠️ Max drawdown triggered, forcing stop.\")\n",
    "            done = True\n",
    "\n",
    "        return self._get_observation(), reward, done, {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        obs = np.concatenate([\n",
    "            [self.amount],\n",
    "            self.stocks,\n",
    "            self.price_array[self.day],\n",
    "            self.tech_array[self.day].flatten()\n",
    "        ])\n",
    "        return obs\n",
    "\n",
    "    def _calculate_total_asset(self):\n",
    "        return self.amount + np.sum(self.stocks * self.price_array[self.day])\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f\"day {self.day}, total_asset: {self.total_asset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### veraion 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 建立強化學習環境，支援單支或多支股票\n",
    "# def create_env_for_stock_np(df, stock_tic, indicators, initial_amount=1e6, if_train=True):\n",
    "#     if isinstance(stock_tic, str):\n",
    "#         stock_list = [stock_tic]\n",
    "#     else:\n",
    "#         stock_list = stock_tic\n",
    "\n",
    "#     df = df[df['tic'].isin(stock_list)].copy()\n",
    "#     df = df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "#     df[indicators] = df[indicators].fillna(0)\n",
    "\n",
    "#     unique_dates = sorted(df['date'].unique())\n",
    "#     price_array = df.pivot(index='date', columns='tic', values='close').reindex(unique_dates).values\n",
    "\n",
    "#     # 技術指標 flatten\n",
    "#     tech_features = []\n",
    "#     for date in unique_dates:\n",
    "#         date_data = df[df['date'] == date]\n",
    "#         row = []\n",
    "#         for tic in stock_list:\n",
    "#             sub = date_data[date_data['tic'] == tic]\n",
    "#             if not sub.empty:\n",
    "#                 row.extend(sub[indicators].values.flatten().tolist())\n",
    "#             else:\n",
    "#                 row.extend([0.0] * len(indicators))\n",
    "#         tech_features.append(row)\n",
    "#     tech_array = np.array(tech_features)\n",
    "\n",
    "#     turbulence_array = np.zeros(len(price_array))\n",
    "\n",
    "#     env = CustomStockTradingEnv(\n",
    "#         config={\n",
    "#             \"price_array\": price_array,\n",
    "#             \"tech_array\": tech_array,\n",
    "#             \"turbulence_array\": turbulence_array,\n",
    "#             \"if_add_price\": True,\n",
    "#             \"if_add_tech\": True,\n",
    "#             \"if_add_turbulence\": False,\n",
    "#             \"risk_indicator_col\": \"turbulence\",\n",
    "#             \"initial_amount\": initial_amount,\n",
    "#             \"buy_cost_pct\": 0.001,\n",
    "#             \"sell_cost_pct\": 0.001,\n",
    "#             \"reward_scaling\": 1e-4,\n",
    "#             \"if_train\": if_train\n",
    "#         }\n",
    "#     )\n",
    "#     return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### veraion 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env_for_stock_np(\n",
    "    df,\n",
    "    stock_tic,\n",
    "    indicators,\n",
    "    initial_amount=1e6,\n",
    "    if_train=True,\n",
    "    max_stock=1e4,\n",
    "    slippage_pct=0.005,  # 滑價 ±0.5%\n",
    "    min_trade_unit=1     # 最小交易單位（整數）\n",
    "):\n",
    "\n",
    "    # ✅ 選擇群內所有股票（多支）\n",
    "    df = df[df['tic'].isin(stock_tic)].copy()\n",
    "    df = df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "\n",
    "    # 補值處理\n",
    "    df[indicators] = df[indicators].fillna(0)\n",
    "\n",
    "    unique_dates = sorted(df['date'].unique())\n",
    "\n",
    "    # 🎯 建構 Numpy 格式\n",
    "    price_array = df.pivot(index='date', columns='tic', values='close').reindex(unique_dates).values\n",
    "    tech_array = df.pivot(index='date', columns='tic', values=indicators).reindex(unique_dates).values\n",
    "    turbulence_array = np.zeros(len(unique_dates))  # 無 turbulence 就全零\n",
    "\n",
    "    # ✅ 實作滑價邏輯（train 才加隨機 slippage）\n",
    "    if if_train:\n",
    "        rng = np.random.default_rng()\n",
    "        price_array = price_array * (1 + rng.normal(loc=0.0, scale=slippage_pct, size=price_array.shape))\n",
    "\n",
    "    # ✅ 將價格為負數/零的異常點清掉\n",
    "    price_array = np.clip(price_array, a_min=1e-3, a_max=None)\n",
    "\n",
    "    # ✅ 整合環境\n",
    "    env = CustomStockTradingEnv(\n",
    "        config={\n",
    "            \"price_array\": price_array,\n",
    "            \"tech_array\": tech_array,\n",
    "            \"turbulence_array\": turbulence_array,\n",
    "            \"if_add_price\": True,\n",
    "            \"if_add_tech\": True,\n",
    "            \"if_add_turbulence\": False,\n",
    "            \"risk_indicator_col\": \"turbulence\",\n",
    "            \"initial_amount\": initial_amount,\n",
    "            \"buy_cost_pct\": 0.001,\n",
    "            \"sell_cost_pct\": 0.001,\n",
    "            \"reward_scaling\": 1e-4,\n",
    "            \"if_train\": if_train,\n",
    "            \"max_stock\": max_stock,             # ✅ 限制最大倉位\n",
    "            \"min_trade_unit\": min_trade_unit    # ✅ 整數交易限制\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 分群訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練特定群組的模型（該群所有股票）\n",
    "def train_model_for_cluster(cluster_id, cluster_labels, df, indicators, model_dir):\n",
    "    group_stocks = [tic for tic, g in cluster_labels.items() if g == cluster_id]\n",
    "    print(f\"🧠 訓練群 {cluster_id}：{group_stocks}\")\n",
    "\n",
    "    # 訓練資料：2021 ~ 2023\n",
    "    train_data = df[(df['date'] >= '2020-01-01') & (df['date'] <= '2023-12-31')]\n",
    "    \n",
    "    env = create_env_for_stock_np(train_data, stock_tic=group_stocks, indicators=indicators, if_train=True)\n",
    "    agent = DRLAgent(env=env)\n",
    "    model = agent.get_model(\"ppo\")\n",
    "    trained_model = agent.train_model(model=model, tb_log_name=f\"ppo_cluster_{cluster_id}\", total_timesteps=300_000)\n",
    "\n",
    "    model_path = os.path.join(model_dir, f\"ppo_cluster_{cluster_id}.zip\")\n",
    "    trained_model.save(model_path)\n",
    "    print(f\"✅ 模型儲存於：{model_path}\")\n",
    "    return model_path\n",
    "\n",
    "# 批次訓練所有群組模型\n",
    "def train_all_models(cluster_labels, df, indicators, model_dir):\n",
    "    for cluster_id in sorted(set(cluster_labels.values())):\n",
    "        train_model_for_cluster(\n",
    "            cluster_id=cluster_id,\n",
    "            cluster_labels=cluster_labels,\n",
    "            df=df,\n",
    "            indicators=indicators,\n",
    "            model_dir=model_dir\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stockstats import StockDataFrame\n",
    "\n",
    "def add_technical_indicators(df, indicators=[\"macd\", \"rsi_30\", \"cci_30\", \"wr_14\"]):\n",
    "    df_list = []\n",
    "    for tic in df['tic'].unique():\n",
    "        sub_df = df[df['tic'] == tic].copy()\n",
    "        sub_df = sub_df.sort_values(\"date\")\n",
    "        stock = StockDataFrame.retype(sub_df)\n",
    "\n",
    "        for indicator in indicators:\n",
    "            try:\n",
    "                sub_df[indicator] = stock[indicator]\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {tic} 無法計算 {indicator}：{e}\")\n",
    "\n",
    "        if 'date' not in sub_df.columns:\n",
    "            sub_df['date'] = sub_df.index\n",
    "\n",
    "        df_list.append(sub_df)\n",
    "\n",
    "    return pd.concat(df_list).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 訓練群 0：['1402.TW']\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.04e+03    |\n",
      "|    ep_rew_mean     | -3.49       |\n",
      "| time/              |             |\n",
      "|    fps             | 3146        |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 0           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.07114006 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -7.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1948         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024732542 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.136        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | -0.021705361 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.339        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1731        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001082914 |\n",
      "|    clip_fraction        | 0.000293    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | 0.00032     |\n",
      "|    reward               | 0.086365364 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.36        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1649         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009119973 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.163        |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000206    |\n",
      "|    reward               | 0.0954152    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.286        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.89        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1600         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016787188 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.199        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000658    |\n",
      "|    reward               | 0.040798042  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.416        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.18        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027612012 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.102        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000746    |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.224        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.31        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1550         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011707796 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0922       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000209    |\n",
      "|    reward               | 0.24055006   |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.374        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.42        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1530         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045820004 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.113        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | -0.02798827  |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.305        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.79        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1520         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029628864 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.181        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -4.56e-05    |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.4          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1511        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005366401 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.18        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | -0.16636579 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.452       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.02        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1501         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010837107 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.137        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 0.000104     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.43         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004394137 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.137        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | 0.00026      |\n",
      "|    reward               | -0.09137097  |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.419        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005184581 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    reward               | -0.14898568 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.313       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.99        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1487         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038551083 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.193        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000723    |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.437        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.87        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1483         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056266934 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    reward               | -0.36902553  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.41         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.92        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1479         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041190786 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.237        |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    reward               | -0.007950851 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.538        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.87        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1477         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030745913 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.255        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00081     |\n",
      "|    reward               | -0.022067023 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.46         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.97        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1475         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027331142 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.28         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | 0.057920564  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.48         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.84        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1473         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011457957 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.213        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000827    |\n",
      "|    reward               | -0.78584707  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.378        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.16        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1468         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026788535 |\n",
      "|    clip_fraction        | 0.00215      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.12         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000221    |\n",
      "|    reward               | 0.13096106   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.39         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.04e+03   |\n",
      "|    ep_rew_mean          | -5.33      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1467       |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00166334 |\n",
      "|    clip_fraction        | 0.00811    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.44      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.222      |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.00144   |\n",
      "|    reward               | 0.11867685 |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 0.414      |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -5.22         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1465          |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 30            |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036735283 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.45         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.196         |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | 0.000309      |\n",
      "|    reward               | 0.18429305    |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 0.447         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.47        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1465         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024050565 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.222        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.43         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.53       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1463        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001589177 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0939      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.000171    |\n",
      "|    reward               | 0.16729753  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.316       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1462        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004536625 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    reward               | -0.28091237 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.44        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.62        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1461         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036089262 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.206        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    reward               | -0.06512016  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.439        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.43        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1461         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017320588 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.217        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000225    |\n",
      "|    reward               | 0.045156643  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.353        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.32        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1460         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020572161 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.267        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000328    |\n",
      "|    reward               | 0.019138427  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.319        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.32       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1457        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002504059 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.246       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 1.27e-05    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -5.54         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1455          |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 42            |\n",
      "|    total_timesteps      | 61440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030027758 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.44         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.192         |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | 0.000103      |\n",
      "|    reward               | -0.388958     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 0.402         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.52        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1454         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045743072 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.171        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.385        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.55        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1454         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022086282 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.192        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000315    |\n",
      "|    reward               | -0.04981116  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.412        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.53        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1452         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011369477 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.329        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000397    |\n",
      "|    reward               | 0.24515095   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.536        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.65        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1452         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025454906 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.187        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.000261    |\n",
      "|    reward               | 0.25256845   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.375        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.67        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1452         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017738276 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.206        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000651    |\n",
      "|    reward               | -0.043616947 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.458        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.66        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1451         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028314856 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.21         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.000442    |\n",
      "|    reward               | 0.75727624   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.368        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.66        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1451         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018519522 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.131        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | 0.012651921  |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 0.307        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.75       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1451        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003410956 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.000433   |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 0.293       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.91       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1451        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003925748 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 0.374       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.92        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1451         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046417564 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    reward               | -0.020811716 |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 0.388        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.95        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1451         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.003489592  |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.157        |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00063     |\n",
      "|    reward               | -0.017373538 |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 0.337        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -6.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1450        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001016939 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 7.46e-05    |\n",
      "|    reward               | -0.02831926 |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 0.378       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -6.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1450        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005977909 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.233       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    reward               | 0.09080424  |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 0.399       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1450         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024644176 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.154        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000435    |\n",
      "|    reward               | 0.48661125   |\n",
      "|    std                  | 0.953        |\n",
      "|    value_loss           | 0.375        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.23        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1449         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027580329 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.194        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.000881    |\n",
      "|    reward               | -0.4005035   |\n",
      "|    std                  | 0.946        |\n",
      "|    value_loss           | 0.411        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.26        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1449         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006810081 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.323        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | 2.13e-05     |\n",
      "|    reward               | 0.30124354   |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 0.546        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.28        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1447         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052867252 |\n",
      "|    clip_fraction        | 0.0356       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.153        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | -0.3307115   |\n",
      "|    std                  | 0.954        |\n",
      "|    value_loss           | 0.446        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1446         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020534294 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.207        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | 2.8e-05      |\n",
      "|    reward               | -0.26073897  |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 0.458        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.19        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1446         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031116647 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.139        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.000323    |\n",
      "|    reward               | 0.01256618   |\n",
      "|    std                  | 0.96         |\n",
      "|    value_loss           | 0.431        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1446         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007493383 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.149        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000384    |\n",
      "|    reward               | 0.4077807    |\n",
      "|    std                  | 0.939        |\n",
      "|    value_loss           | 0.37         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -6.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003711887 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.238       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    reward               | -0.11256126 |\n",
      "|    std                  | 0.936       |\n",
      "|    value_loss           | 0.516       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.99        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014799525 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.212        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.000291    |\n",
      "|    reward               | 0.057959888  |\n",
      "|    std                  | 0.928        |\n",
      "|    value_loss           | 0.445        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025379295 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.276        |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.000877    |\n",
      "|    reward               | 0.018773997  |\n",
      "|    std                  | 0.915        |\n",
      "|    value_loss           | 0.547        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -6.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004166646 |\n",
      "|    clip_fraction        | 0.00928     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.252       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.000733   |\n",
      "|    reward               | 0.1803513   |\n",
      "|    std                  | 0.917       |\n",
      "|    value_loss           | 0.552       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -6.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004686719 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.252       |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    reward               | -0.04762917 |\n",
      "|    std                  | 0.909       |\n",
      "|    value_loss           | 0.554       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012533453 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.202        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.000159    |\n",
      "|    reward               | 0.12542054   |\n",
      "|    std                  | 0.918        |\n",
      "|    value_loss           | 0.542        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037386885 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.357        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.000882    |\n",
      "|    reward               | 0.076710775  |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 0.55         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.89       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006327529 |\n",
      "|    clip_fraction        | 0.0353      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.285       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | -0.083224   |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 0.509       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.74       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004164836 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.445       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.000627   |\n",
      "|    reward               | 0.11472261  |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 0.519       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005199627 |\n",
      "|    clip_fraction        | 0.0306      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.303       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    reward               | 0.10856009  |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 0.564       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.55       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002878557 |\n",
      "|    clip_fraction        | 0.00405     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.254       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.000446   |\n",
      "|    reward               | 0.19420427  |\n",
      "|    std                  | 0.887       |\n",
      "|    value_loss           | 0.549       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002856797 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.351       |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    reward               | 0.709415    |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 0.599       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.28        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051438794 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.243        |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    reward               | 0.14076482   |\n",
      "|    std                  | 0.888        |\n",
      "|    value_loss           | 0.56         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004160961  |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.319        |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    reward               | 0.0070911963 |\n",
      "|    std                  | 0.88         |\n",
      "|    value_loss           | 0.61         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002501667 |\n",
      "|    clip_fraction        | 0.00703     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.328       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.000135   |\n",
      "|    reward               | 0.17212924  |\n",
      "|    std                  | 0.883       |\n",
      "|    value_loss           | 0.581       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -4.94       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005994778 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.279       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | -0.06490088 |\n",
      "|    std                  | 0.88        |\n",
      "|    value_loss           | 0.588       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023916417 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.294        |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.000211    |\n",
      "|    reward               | 0.14494222   |\n",
      "|    std                  | 0.875        |\n",
      "|    value_loss           | 0.572        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.61        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017072953 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.25         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | 0.000256     |\n",
      "|    reward               | -0.16618423  |\n",
      "|    std                  | 0.879        |\n",
      "|    value_loss           | 0.588        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -4.41       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002349596 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.258       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    reward               | -0.75683266 |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 0.565       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.29        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005675163  |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.277        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -0.048695914 |\n",
      "|    std                  | 0.897        |\n",
      "|    value_loss           | 0.588        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.97        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1444         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034742157 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.202        |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    reward               | 0.20832308   |\n",
      "|    std                  | 0.893        |\n",
      "|    value_loss           | 0.589        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -3.71         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1445          |\n",
      "|    iterations           | 72            |\n",
      "|    time_elapsed         | 102           |\n",
      "|    total_timesteps      | 147456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067482644 |\n",
      "|    clip_fraction        | 0.00249       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.31         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.286         |\n",
      "|    n_updates            | 710           |\n",
      "|    policy_gradient_loss | 9.04e-05      |\n",
      "|    reward               | -0.23349315   |\n",
      "|    std                  | 0.905         |\n",
      "|    value_loss           | 0.549         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -3.61         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1445          |\n",
      "|    iterations           | 73            |\n",
      "|    time_elapsed         | 103           |\n",
      "|    total_timesteps      | 149504        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035524333 |\n",
      "|    clip_fraction        | 0.00171       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.32         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.226         |\n",
      "|    n_updates            | 720           |\n",
      "|    policy_gradient_loss | 6.91e-05      |\n",
      "|    reward               | -0.15075184   |\n",
      "|    std                  | 0.904         |\n",
      "|    value_loss           | 0.543         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -3.33         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1445          |\n",
      "|    iterations           | 74            |\n",
      "|    time_elapsed         | 104           |\n",
      "|    total_timesteps      | 151552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010708702 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.32         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.143         |\n",
      "|    n_updates            | 730           |\n",
      "|    policy_gradient_loss | 0.000237      |\n",
      "|    reward               | -0.0074931392 |\n",
      "|    std                  | 0.913         |\n",
      "|    value_loss           | 0.547         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027784542 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.245        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | 3.32e-05     |\n",
      "|    reward               | -0.45992765  |\n",
      "|    std                  | 0.911        |\n",
      "|    value_loss           | 0.572        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.96        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1445         |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010729363 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.295        |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.000458    |\n",
      "|    reward               | -0.3388523   |\n",
      "|    std                  | 0.892        |\n",
      "|    value_loss           | 0.599        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -2.77         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1445          |\n",
      "|    iterations           | 77            |\n",
      "|    time_elapsed         | 109           |\n",
      "|    total_timesteps      | 157696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0066423723  |\n",
      "|    clip_fraction        | 0.0235        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.3          |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.255         |\n",
      "|    n_updates            | 760           |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    reward               | -0.0012750464 |\n",
      "|    std                  | 0.88          |\n",
      "|    value_loss           | 0.573         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.72        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1443         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036959827 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.235        |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    reward               | 0.041790143  |\n",
      "|    std                  | 0.882        |\n",
      "|    value_loss           | 0.638        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -2.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1442        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003037727 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.283       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | -0.62032783 |\n",
      "|    std                  | 0.872       |\n",
      "|    value_loss           | 0.626       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.39        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034764751 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.246        |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.000892    |\n",
      "|    reward               | 0.13707495   |\n",
      "|    std                  | 0.869        |\n",
      "|    value_loss           | 0.537        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.17        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031483755 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.256        |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.000656    |\n",
      "|    reward               | -0.08168858  |\n",
      "|    std                  | 0.871        |\n",
      "|    value_loss           | 0.566        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037459692 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.338        |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.000855    |\n",
      "|    reward               | 0.02679478   |\n",
      "|    std                  | 0.867        |\n",
      "|    value_loss           | 0.607        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.95        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017031602 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.166        |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.000983    |\n",
      "|    reward               | 0.63719237   |\n",
      "|    std                  | 0.861        |\n",
      "|    value_loss           | 0.601        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.68       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1442        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005981572 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.246       |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -0.17521806 |\n",
      "|    std                  | 0.855       |\n",
      "|    value_loss           | 0.627       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.43        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040524867 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.274        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.000152    |\n",
      "|    reward               | -0.08785336  |\n",
      "|    std                  | 0.858        |\n",
      "|    value_loss           | 0.621        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.23        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035849896 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.29         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | -0.23830187  |\n",
      "|    std                  | 0.858        |\n",
      "|    value_loss           | 0.567        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016337964 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.136        |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    reward               | 0.16413838   |\n",
      "|    std                  | 0.829        |\n",
      "|    value_loss           | 0.542        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.884       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024863915 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.299        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    reward               | -0.04677154  |\n",
      "|    std                  | 0.825        |\n",
      "|    value_loss           | 0.571        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -0.65       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1442        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001113179 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.259       |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | 9.51e-05    |\n",
      "|    reward               | 0.044404842 |\n",
      "|    std                  | 0.821       |\n",
      "|    value_loss           | 0.6         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.33        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046254545 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.196        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | -0.31269735  |\n",
      "|    std                  | 0.812        |\n",
      "|    value_loss           | 0.6          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.138       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030093405 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.279        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.000546    |\n",
      "|    reward               | 0.37288997   |\n",
      "|    std                  | 0.806        |\n",
      "|    value_loss           | 0.606        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.0915       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014955406 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.262        |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | -0.029743318 |\n",
      "|    std                  | 0.831        |\n",
      "|    value_loss           | 0.585        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.391       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1442        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00289062  |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.231       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    reward               | 0.061939906 |\n",
      "|    std                  | 0.822       |\n",
      "|    value_loss           | 0.634       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.651        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049763634 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.296        |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    reward               | -0.3567864   |\n",
      "|    std                  | 0.815        |\n",
      "|    value_loss           | 0.643        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 0.805         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1442          |\n",
      "|    iterations           | 95            |\n",
      "|    time_elapsed         | 134           |\n",
      "|    total_timesteps      | 194560        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072487455 |\n",
      "|    clip_fraction        | 0.014         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.346         |\n",
      "|    n_updates            | 940           |\n",
      "|    policy_gradient_loss | -0.00113      |\n",
      "|    reward               | 0.56198436    |\n",
      "|    std                  | 0.835         |\n",
      "|    value_loss           | 0.612         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 1.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1442        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002377043 |\n",
      "|    clip_fraction        | 0.00747     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.321       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.000169   |\n",
      "|    reward               | 0.121448755 |\n",
      "|    std                  | 0.832       |\n",
      "|    value_loss           | 0.606       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.29         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033031339 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.326        |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000917    |\n",
      "|    reward               | 0.06772298   |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 0.636        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.49         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033924468 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.319        |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    reward               | 0.08928018   |\n",
      "|    std                  | 0.836        |\n",
      "|    value_loss           | 0.636        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.63         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064987307 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.22         |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    reward               | 0.0765473    |\n",
      "|    std                  | 0.837        |\n",
      "|    value_loss           | 0.626        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.85         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046943445 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.21         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    reward               | -0.7318144   |\n",
      "|    std                  | 0.834        |\n",
      "|    value_loss           | 0.613        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 2.01          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1442          |\n",
      "|    iterations           | 101           |\n",
      "|    time_elapsed         | 143           |\n",
      "|    total_timesteps      | 206848        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073770876 |\n",
      "|    clip_fraction        | 0.00181       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.24         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.369         |\n",
      "|    n_updates            | 1000          |\n",
      "|    policy_gradient_loss | 5.28e-05      |\n",
      "|    reward               | -0.45443323   |\n",
      "|    std                  | 0.835         |\n",
      "|    value_loss           | 0.625         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.2          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053743394 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.298        |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    reward               | -0.083889216 |\n",
      "|    std                  | 0.829        |\n",
      "|    value_loss           | 0.618        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.39         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1442         |\n",
      "|    iterations           | 103          |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 210944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004665922 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.164        |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | 0.000236     |\n",
      "|    reward               | -0.09965875  |\n",
      "|    std                  | 0.827        |\n",
      "|    value_loss           | 0.629        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.64         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1441         |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001627267 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.279        |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | 0.000267     |\n",
      "|    reward               | 0.13066563   |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 0.65         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.86         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1441         |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009450518 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.335        |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | 0.000176     |\n",
      "|    reward               | 0.42597604   |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 0.621        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.07         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1440         |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014651566 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.376        |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    reward               | -0.51925176  |\n",
      "|    std                  | 0.822        |\n",
      "|    value_loss           | 0.611        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.16         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1439         |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038818629 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.302        |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | 2.91e-06     |\n",
      "|    reward               | 0.09814043   |\n",
      "|    std                  | 0.825        |\n",
      "|    value_loss           | 0.598        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.37         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1439         |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033643981 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.279        |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.000712    |\n",
      "|    reward               | -0.08756394  |\n",
      "|    std                  | 0.83         |\n",
      "|    value_loss           | 0.602        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 3.45        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1439        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004741751 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.301       |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | -0.10993713 |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 0.608       |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 3.5           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1438          |\n",
      "|    iterations           | 110           |\n",
      "|    time_elapsed         | 156           |\n",
      "|    total_timesteps      | 225280        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015767259 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.23          |\n",
      "|    n_updates            | 1090          |\n",
      "|    policy_gradient_loss | 3.27e-05      |\n",
      "|    reward               | 0.07387622    |\n",
      "|    std                  | 0.826         |\n",
      "|    value_loss           | 0.61          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.63         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1438         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015693097 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.291        |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | 4.67e-05     |\n",
      "|    reward               | -0.17640075  |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 0.611        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.74         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1437         |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005797973 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.236        |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | 0.000324     |\n",
      "|    reward               | -0.30429515  |\n",
      "|    std                  | 0.84         |\n",
      "|    value_loss           | 0.621        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.82         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1437         |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032774077 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.527        |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.000296    |\n",
      "|    reward               | 0.3809077    |\n",
      "|    std                  | 0.843        |\n",
      "|    value_loss           | 0.613        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.88         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1436         |\n",
      "|    iterations           | 114          |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046814918 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.447        |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | 0.045165416  |\n",
      "|    std                  | 0.837        |\n",
      "|    value_loss           | 0.609        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.9          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1436         |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009521083 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.351        |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -2.12e-05    |\n",
      "|    reward               | 0.31489283   |\n",
      "|    std                  | 0.843        |\n",
      "|    value_loss           | 0.61         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 3.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1435        |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004867476 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.187       |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | 0.08253347  |\n",
      "|    std                  | 0.838       |\n",
      "|    value_loss           | 0.548       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 4.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1435        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002337927 |\n",
      "|    clip_fraction        | 0.00356     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | 0.0002      |\n",
      "|    reward               | -0.19540018 |\n",
      "|    std                  | 0.842       |\n",
      "|    value_loss           | 0.623       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.13         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1434         |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024642022 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.415        |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000492    |\n",
      "|    reward               | -0.017772097 |\n",
      "|    std                  | 0.845        |\n",
      "|    value_loss           | 0.601        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.11         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1433         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031874923 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.294        |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | 0.0686439    |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 0.608        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.14         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1433         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024618593 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.285        |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.000244    |\n",
      "|    reward               | 0.73653644   |\n",
      "|    std                  | 0.842        |\n",
      "|    value_loss           | 0.62         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.19         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1433         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036465987 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.326        |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.000829    |\n",
      "|    reward               | 0.3706962    |\n",
      "|    std                  | 0.836        |\n",
      "|    value_loss           | 0.604        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 4.19          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1432          |\n",
      "|    iterations           | 122           |\n",
      "|    time_elapsed         | 174           |\n",
      "|    total_timesteps      | 249856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033275437 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.24         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.349         |\n",
      "|    n_updates            | 1210          |\n",
      "|    policy_gradient_loss | 0.000125      |\n",
      "|    reward               | -0.10471091   |\n",
      "|    std                  | 0.829         |\n",
      "|    value_loss           | 0.629         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.21         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1432         |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033125426 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.167        |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.000185    |\n",
      "|    reward               | 0.23127073   |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 0.614        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 4.29          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1431          |\n",
      "|    iterations           | 124           |\n",
      "|    time_elapsed         | 177           |\n",
      "|    total_timesteps      | 253952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047971873 |\n",
      "|    clip_fraction        | 0.000977      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.338         |\n",
      "|    n_updates            | 1230          |\n",
      "|    policy_gradient_loss | 0.000188      |\n",
      "|    reward               | -0.23484772   |\n",
      "|    std                  | 0.824         |\n",
      "|    value_loss           | 0.633         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 4.33          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1431          |\n",
      "|    iterations           | 125           |\n",
      "|    time_elapsed         | 178           |\n",
      "|    total_timesteps      | 256000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083854864 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.22         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.309         |\n",
      "|    n_updates            | 1240          |\n",
      "|    policy_gradient_loss | -7.13e-05     |\n",
      "|    reward               | -0.03901104   |\n",
      "|    std                  | 0.816         |\n",
      "|    value_loss           | 0.619         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 4.35          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1431          |\n",
      "|    iterations           | 126           |\n",
      "|    time_elapsed         | 180           |\n",
      "|    total_timesteps      | 258048        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3584692e-05 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.21         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.247         |\n",
      "|    n_updates            | 1250          |\n",
      "|    policy_gradient_loss | 2.9e-05       |\n",
      "|    reward               | 0.009291546   |\n",
      "|    std                  | 0.814         |\n",
      "|    value_loss           | 0.627         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 4.43        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1430        |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003431181 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.393       |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.000981   |\n",
      "|    reward               | -0.18467683 |\n",
      "|    std                  | 0.821       |\n",
      "|    value_loss           | 0.614       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.51         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1430         |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024527423 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.279        |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | -0.000485    |\n",
      "|    reward               | -0.21875674  |\n",
      "|    std                  | 0.82         |\n",
      "|    value_loss           | 0.622        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.59         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1430         |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 184          |\n",
      "|    total_timesteps      | 264192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040601958 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.288        |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    reward               | 0.26723063   |\n",
      "|    std                  | 0.815        |\n",
      "|    value_loss           | 0.628        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 4.61          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1429          |\n",
      "|    iterations           | 130           |\n",
      "|    time_elapsed         | 186           |\n",
      "|    total_timesteps      | 266240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016041053 |\n",
      "|    clip_fraction        | 0.00503       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.21         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.324         |\n",
      "|    n_updates            | 1290          |\n",
      "|    policy_gradient_loss | -7.92e-05     |\n",
      "|    reward               | 0.15185928    |\n",
      "|    std                  | 0.809         |\n",
      "|    value_loss           | 0.626         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 4.67        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1429        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002122286 |\n",
      "|    clip_fraction        | 0.0084      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.192       |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.000532   |\n",
      "|    reward               | -0.2612697  |\n",
      "|    std                  | 0.804       |\n",
      "|    value_loss           | 0.616       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 4.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1429        |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002593083 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.316       |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00108    |\n",
      "|    reward               | 0.30611673  |\n",
      "|    std                  | 0.801       |\n",
      "|    value_loss           | 0.622       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.9          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1428         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023710376 |\n",
      "|    clip_fraction        | 0.00532      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.382        |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | 1.52e-05     |\n",
      "|    reward               | -0.36730856  |\n",
      "|    std                  | 0.796        |\n",
      "|    value_loss           | 0.617        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 4.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1428        |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004825058 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.246       |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    reward               | -0.25868732 |\n",
      "|    std                  | 0.793       |\n",
      "|    value_loss           | 0.631       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.97         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1428         |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 276480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039368416 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.214        |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    reward               | 0.8750791    |\n",
      "|    std                  | 0.787        |\n",
      "|    value_loss           | 0.6          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1428         |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023256782 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.258        |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.000714    |\n",
      "|    reward               | 0.48491368   |\n",
      "|    std                  | 0.781        |\n",
      "|    value_loss           | 0.622        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 5.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1427        |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003423514 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.431       |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    reward               | 0.29639435  |\n",
      "|    std                  | 0.778       |\n",
      "|    value_loss           | 0.611       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.01         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1427         |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002520805 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.292        |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    reward               | 0.27557355   |\n",
      "|    std                  | 0.78         |\n",
      "|    value_loss           | 0.614        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.03         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1427         |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041056443 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.453        |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | 0.19048254   |\n",
      "|    std                  | 0.78         |\n",
      "|    value_loss           | 0.628        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.03         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1427         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011824172 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.237        |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | 0.000148     |\n",
      "|    reward               | -0.06594012  |\n",
      "|    std                  | 0.795        |\n",
      "|    value_loss           | 0.628        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 5.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1427        |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003041333 |\n",
      "|    clip_fraction        | 0.00781     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.198       |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | 4.48e-05    |\n",
      "|    reward               | -0.04153093 |\n",
      "|    std                  | 0.8         |\n",
      "|    value_loss           | 0.622       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.08         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1426         |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029913164 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.283        |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.000995    |\n",
      "|    reward               | 0.51309574   |\n",
      "|    std                  | 0.794        |\n",
      "|    value_loss           | 0.608        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.08         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1425         |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006310201 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.303        |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    reward               | -0.16508129  |\n",
      "|    std                  | 0.796        |\n",
      "|    value_loss           | 0.617        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 5.09        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1424        |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002530253 |\n",
      "|    clip_fraction        | 0.0278      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.294       |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    reward               | 0.22792763  |\n",
      "|    std                  | 0.797       |\n",
      "|    value_loss           | 0.643       |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 5.13          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1424          |\n",
      "|    iterations           | 145           |\n",
      "|    time_elapsed         | 208           |\n",
      "|    total_timesteps      | 296960        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031455237 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.19         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.222         |\n",
      "|    n_updates            | 1440          |\n",
      "|    policy_gradient_loss | 0.000309      |\n",
      "|    reward               | -0.3450216    |\n",
      "|    std                  | 0.789         |\n",
      "|    value_loss           | 0.543         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.13         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1424         |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006566873 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.326        |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | 0.000212     |\n",
      "|    reward               | -0.29693383  |\n",
      "|    std                  | 0.798        |\n",
      "|    value_loss           | 0.606        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.12         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1424         |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032523444 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.297        |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.000457    |\n",
      "|    reward               | -0.13235931  |\n",
      "|    std                  | 0.795        |\n",
      "|    value_loss           | 0.64         |\n",
      "------------------------------------------\n",
      "✅ 模型儲存於：E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_0.zip\n",
      "🧠 訓練群 1：['2301.TW']\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.04e+03  |\n",
      "|    ep_rew_mean     | 41.5      |\n",
      "| time/              |           |\n",
      "|    fps             | 3052      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | -0.778896 |\n",
      "----------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 10.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1897        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001979369 |\n",
      "|    clip_fraction        | 0.00947     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.00329     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.58        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.000338   |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 17.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1682         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025340584 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.0682       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.96         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | -1.7332618   |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 9.59         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033340463 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.0578       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.54         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | 7.6e-05      |\n",
      "|    reward               | 7.371438     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 6.7          |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 21.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1536         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041267937 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.00309      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.48         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    reward               | 0.21709515   |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 13.1         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 27.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1514          |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 8             |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014435148 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | 0.0165        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 7.74          |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | 0.000167      |\n",
      "|    reward               | -0.07290949   |\n",
      "|    std                  | 0.971         |\n",
      "|    value_loss           | 15.1          |\n",
      "-------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 22.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031587197 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -0.0341      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.6          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0002      |\n",
      "|    reward               | -0.6596469   |\n",
      "|    std                  | 0.967        |\n",
      "|    value_loss           | 8.86         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 26.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1480        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002559908 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.2         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 8.75        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 26.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1469         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053535947 |\n",
      "|    clip_fraction        | 0.0459       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | -0.000424    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | 0.22599845   |\n",
      "|    std                  | 0.946        |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 26.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1461        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005899566 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.00943    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.22        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    reward               | 0.006043944 |\n",
      "|    std                  | 0.94        |\n",
      "|    value_loss           | 9.65        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 26.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1456          |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00089215103 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.35         |\n",
      "|    explained_variance   | 0.0218        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.36          |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000245     |\n",
      "|    reward               | -0.44341865   |\n",
      "|    std                  | 0.93          |\n",
      "|    value_loss           | 14.8          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 28.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1450          |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058963906 |\n",
      "|    clip_fraction        | 0.017         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.35         |\n",
      "|    explained_variance   | 0.0731        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.96          |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.00104      |\n",
      "|    reward               | 0.0837494     |\n",
      "|    std                  | 0.939         |\n",
      "|    value_loss           | 13.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 30.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1444         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018833189 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.00345     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.25         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000805    |\n",
      "|    reward               | 1.1211926    |\n",
      "|    std                  | 0.933        |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 30          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1440        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002378419 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.000258   |\n",
      "|    reward               | -0.61131144 |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 31.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1435        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003280471 |\n",
      "|    clip_fraction        | 0.00313     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.0953      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.6         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.000171   |\n",
      "|    reward               | 0.09065482  |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 30.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1433         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032570218 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.0703      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.28         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000278    |\n",
      "|    reward               | 0.27085376   |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 10.7         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 28.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1430         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039464775 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.0248      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.87         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | -0.39080566  |\n",
      "|    std                  | 0.935        |\n",
      "|    value_loss           | 8.13         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 27.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1429        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002417084 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.59        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | 0.47155547  |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 27.6          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1427          |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 27            |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022694693 |\n",
      "|    clip_fraction        | 0.00249       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.34         |\n",
      "|    explained_variance   | 0.103         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.28          |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | 2.11e-05      |\n",
      "|    reward               | 1.9145318     |\n",
      "|    std                  | 0.924         |\n",
      "|    value_loss           | 9.05          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 29.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1424         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042071547 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.0276       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.988        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -0.41104913  |\n",
      "|    std                  | 0.923        |\n",
      "|    value_loss           | 11.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 30.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1422         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045170668 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.00327      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.98         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 0.3272113    |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 13.9         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 30.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1421         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067225415 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.8          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | 2.5e-05      |\n",
      "|    reward               | 0.05834198   |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 15.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 31.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1419         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058362186 |\n",
      "|    clip_fraction        | 0.0518       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | -0.23102725  |\n",
      "|    std                  | 0.92         |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 32.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1419         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017986988 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.57         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000852    |\n",
      "|    reward               | -0.09775626  |\n",
      "|    std                  | 0.915        |\n",
      "|    value_loss           | 14.3         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 32.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1419         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071516084 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.06         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | -0.26448473  |\n",
      "|    std                  | 0.908        |\n",
      "|    value_loss           | 19.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 33.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1419        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006027011 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    reward               | -0.02204216 |\n",
      "|    std                  | 0.906       |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 34            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1419          |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 38            |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065071695 |\n",
      "|    clip_fraction        | 0.00107       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.33         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.6          |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | 4.76e-05      |\n",
      "|    reward               | 0.0           |\n",
      "|    std                  | 0.924         |\n",
      "|    value_loss           | 17.4          |\n",
      "-------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 33.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1417         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051169535 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.12         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | 0.43257502   |\n",
      "|    std                  | 0.92         |\n",
      "|    value_loss           | 19.2         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 34.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1417         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022616321 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000456    |\n",
      "|    reward               | 0.016046196  |\n",
      "|    std                  | 0.927        |\n",
      "|    value_loss           | 11.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 34.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1416         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022451326 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.91         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    reward               | -0.05514821  |\n",
      "|    std                  | 0.939        |\n",
      "|    value_loss           | 25.5         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 34.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1416         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016761795 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.52         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000802    |\n",
      "|    reward               | 0.22674623   |\n",
      "|    std                  | 0.93         |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.03e+03   |\n",
      "|    ep_rew_mean          | 35         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1415       |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00512797 |\n",
      "|    clip_fraction        | 0.0124     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | 0.0929     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.29       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.000712  |\n",
      "|    reward               | 0.2341487  |\n",
      "|    std                  | 0.918      |\n",
      "|    value_loss           | 17.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 35.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1415         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007842055 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.34         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | 0.000107     |\n",
      "|    reward               | 0.46428755   |\n",
      "|    std                  | 0.911        |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 36           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1413         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031646767 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.7         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.000765    |\n",
      "|    reward               | -0.34774256  |\n",
      "|    std                  | 0.912        |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 36.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1413         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023026168 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.56         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000643    |\n",
      "|    reward               | 0.32004106   |\n",
      "|    std                  | 0.909        |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 36.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1413        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005639949 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.45        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | -0.40733635 |\n",
      "|    std                  | 0.897       |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 36.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1412         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040155416 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.0702       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6            |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    reward               | -0.3656678   |\n",
      "|    std                  | 0.896        |\n",
      "|    value_loss           | 18.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 37           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1410         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068283426 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.0458       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.71         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | 0.000169     |\n",
      "|    reward               | -1.2340697   |\n",
      "|    std                  | 0.891        |\n",
      "|    value_loss           | 14.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 37.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1410         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040840595 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | -0.3404694   |\n",
      "|    std                  | 0.891        |\n",
      "|    value_loss           | 21.7         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 37.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1410         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011573359 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.04         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.000649    |\n",
      "|    reward               | -0.19935893  |\n",
      "|    std                  | 0.873        |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 38.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1408         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024654623 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.2          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | 8.59e-05     |\n",
      "|    reward               | 0.3903756    |\n",
      "|    std                  | 0.867        |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 38.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1408         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046089487 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 23.7         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000676    |\n",
      "|    reward               | 0.40991333   |\n",
      "|    std                  | 0.867        |\n",
      "|    value_loss           | 25.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 39.6          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1407          |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 62            |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037798862 |\n",
      "|    clip_fraction        | 0.00952       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.28         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 11.8          |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.000119     |\n",
      "|    reward               | -0.36399364   |\n",
      "|    std                  | 0.867         |\n",
      "|    value_loss           | 16.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 39.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1405         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054128896 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.09         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    reward               | 0.23076428   |\n",
      "|    std                  | 0.868        |\n",
      "|    value_loss           | 22.4         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 39.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1403         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035882804 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | -0.023       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.64         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00043     |\n",
      "|    reward               | -0.9000252   |\n",
      "|    std                  | 0.866        |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 39.6          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1402          |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 67            |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037332336 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.27         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 12.1          |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -1.6e-05      |\n",
      "|    reward               | 0.0978967     |\n",
      "|    std                  | 0.857         |\n",
      "|    value_loss           | 20.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 39.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1402         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029896218 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000143    |\n",
      "|    reward               | 0.76561236   |\n",
      "|    std                  | 0.854        |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 40           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1402         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004211259  |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.2          |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.000689    |\n",
      "|    reward               | -0.027883999 |\n",
      "|    std                  | 0.842        |\n",
      "|    value_loss           | 19.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 40.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1402          |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 71            |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041102208 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.24         |\n",
      "|    explained_variance   | 0.0234        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.4          |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | 0.000224      |\n",
      "|    reward               | 0.40493166    |\n",
      "|    std                  | 0.834         |\n",
      "|    value_loss           | 12.5          |\n",
      "-------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 39.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1399        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004325441 |\n",
      "|    clip_fraction        | 0.00469     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 6.16e-05    |\n",
      "|    reward               | -0.71304464 |\n",
      "|    std                  | 0.83        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 40.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1399         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004321085 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.0504       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.79         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.000435    |\n",
      "|    reward               | 0.41407123   |\n",
      "|    std                  | 0.82         |\n",
      "|    value_loss           | 16           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 41.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1399        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00820943  |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.96        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    reward               | -0.24746896 |\n",
      "|    std                  | 0.814       |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 42.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1399          |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 77            |\n",
      "|    total_timesteps      | 108544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068725145 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.21         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.29          |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | -6.97e-05     |\n",
      "|    reward               | 0.35394946    |\n",
      "|    std                  | 0.804         |\n",
      "|    value_loss           | 18.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 43.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1398        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002466387 |\n",
      "|    clip_fraction        | 0.00972     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00065    |\n",
      "|    reward               | -0.14438803 |\n",
      "|    std                  | 0.802       |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 43.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1398         |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025332922 |\n",
      "|    clip_fraction        | 0.00513      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | 2.82e-05     |\n",
      "|    reward               | 0.32786223   |\n",
      "|    std                  | 0.804        |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 43.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1396        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005532733 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    reward               | 0.95133406  |\n",
      "|    std                  | 0.797       |\n",
      "|    value_loss           | 20          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 45.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1396         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066256337 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.01         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | 0.000332     |\n",
      "|    reward               | -0.29192847  |\n",
      "|    std                  | 0.794        |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 45.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1395         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064643677 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.45         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 2.874817     |\n",
      "|    std                  | 0.788        |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 46          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009135781 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.34        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    reward               | 0.37751833  |\n",
      "|    std                  | 0.787       |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 46.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1395         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016936761 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00012     |\n",
      "|    reward               | -2.8159685   |\n",
      "|    std                  | 0.783        |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 47.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1395         |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015788504 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.4         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | 0.00023      |\n",
      "|    reward               | 6.6428194    |\n",
      "|    std                  | 0.783        |\n",
      "|    value_loss           | 18.1         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 47.5          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1392          |\n",
      "|    iterations           | 62            |\n",
      "|    time_elapsed         | 91            |\n",
      "|    total_timesteps      | 126976        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00036845988 |\n",
      "|    clip_fraction        | 0.00615       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.18         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 9.77          |\n",
      "|    n_updates            | 610           |\n",
      "|    policy_gradient_loss | -0.000592     |\n",
      "|    reward               | 1.8503624     |\n",
      "|    std                  | 0.797         |\n",
      "|    value_loss           | 18.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 47.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1393         |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009709739 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.8         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | 3.68e-05     |\n",
      "|    reward               | 2.7856164    |\n",
      "|    std                  | 0.807        |\n",
      "|    value_loss           | 20.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 47.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1392         |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034393435 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.9         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.000593    |\n",
      "|    reward               | 0.38335562   |\n",
      "|    std                  | 0.805        |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 48.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1393         |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032080163 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.25         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    reward               | -0.25385198  |\n",
      "|    std                  | 0.808        |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | 49.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1393          |\n",
      "|    iterations           | 66            |\n",
      "|    time_elapsed         | 97            |\n",
      "|    total_timesteps      | 135168        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025397842 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.2          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.27          |\n",
      "|    n_updates            | 650           |\n",
      "|    policy_gradient_loss | 0.00022       |\n",
      "|    reward               | 0.67417103    |\n",
      "|    std                  | 0.799         |\n",
      "|    value_loss           | 17.7          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 50.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1392        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003021789 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | -0.39507443 |\n",
      "|    std                  | 0.799       |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 51.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1391         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028517165 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.000967    |\n",
      "|    reward               | -0.18117331  |\n",
      "|    std                  | 0.799        |\n",
      "|    value_loss           | 20.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 52.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1391         |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053884853 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    reward               | 0.05834198   |\n",
      "|    std                  | 0.801        |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 53           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1391         |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002535769 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.77         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | 0.000147     |\n",
      "|    reward               | -0.9199896   |\n",
      "|    std                  | 0.803        |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 53           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1391         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049398355 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.71         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    reward               | 1.1738906    |\n",
      "|    std                  | 0.802        |\n",
      "|    value_loss           | 20.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 53.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1391          |\n",
      "|    iterations           | 72            |\n",
      "|    time_elapsed         | 105           |\n",
      "|    total_timesteps      | 147456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00090266566 |\n",
      "|    clip_fraction        | 0.0194        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.2          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 6.85          |\n",
      "|    n_updates            | 710           |\n",
      "|    policy_gradient_loss | -0.00146      |\n",
      "|    reward               | 1.1801461     |\n",
      "|    std                  | 0.803         |\n",
      "|    value_loss           | 21.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 53.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1392         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022480893 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.000488    |\n",
      "|    reward               | -0.06694995  |\n",
      "|    std                  | 0.786        |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 54.2          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1390          |\n",
      "|    iterations           | 74            |\n",
      "|    time_elapsed         | 108           |\n",
      "|    total_timesteps      | 151552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033405176 |\n",
      "|    clip_fraction        | 0.00522       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.19         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.6          |\n",
      "|    n_updates            | 730           |\n",
      "|    policy_gradient_loss | -0.000187     |\n",
      "|    reward               | -1.2175224    |\n",
      "|    std                  | 0.8           |\n",
      "|    value_loss           | 23.7          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 54.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1390        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004420396 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.000984   |\n",
      "|    reward               | -0.15979083 |\n",
      "|    std                  | 0.803       |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 55.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1390         |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017185127 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.4         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | 0.000124     |\n",
      "|    reward               | 0.4583209    |\n",
      "|    std                  | 0.809        |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 55.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1390        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005475051 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    reward               | 0.124436736 |\n",
      "|    std                  | 0.81        |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 55.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1389         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046904306 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.000422    |\n",
      "|    reward               | -0.1788767   |\n",
      "|    std                  | 0.808        |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 56.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1390         |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033132476 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -6.2e-05     |\n",
      "|    reward               | 0.47952515   |\n",
      "|    std                  | 0.809        |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 56.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1389        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006896029 |\n",
      "|    clip_fraction        | 0.0267      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | 1.1947994   |\n",
      "|    std                  | 0.815       |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 57.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1389         |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073878565 |\n",
      "|    clip_fraction        | 0.0552       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.8         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    reward               | 0.5970558    |\n",
      "|    std                  | 0.813        |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 58.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1389         |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034845513 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.000322    |\n",
      "|    reward               | 0.2769866    |\n",
      "|    std                  | 0.807        |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 58.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1388         |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055442294 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | -0.32868782  |\n",
      "|    std                  | 0.804        |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 58.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1388        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006208047 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    reward               | 0.09978209  |\n",
      "|    std                  | 0.806       |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 59.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1388         |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030920901 |\n",
      "|    clip_fraction        | 0.0523       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.8         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    reward               | -0.003953288 |\n",
      "|    std                  | 0.807        |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 59.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1387          |\n",
      "|    iterations           | 86            |\n",
      "|    time_elapsed         | 126           |\n",
      "|    total_timesteps      | 176128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088446506 |\n",
      "|    clip_fraction        | 0.0107        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.21         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 3.72          |\n",
      "|    n_updates            | 850           |\n",
      "|    policy_gradient_loss | -0.000801     |\n",
      "|    reward               | 0.70778644    |\n",
      "|    std                  | 0.825         |\n",
      "|    value_loss           | 22.4          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 59.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1386         |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031008646 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.53         |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.000201    |\n",
      "|    reward               | 0.32774925   |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 24.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 60.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1386         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011224565 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.36         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | 0.000429     |\n",
      "|    reward               | 0.07944363   |\n",
      "|    std                  | 0.826        |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 60.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001164776 |\n",
      "|    clip_fraction        | 0.00293     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.63        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -8.96e-05   |\n",
      "|    reward               | 0.87222505  |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 60.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002173942 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.000953   |\n",
      "|    reward               | 1.4132879   |\n",
      "|    std                  | 0.822       |\n",
      "|    value_loss           | 21.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 60.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043190885 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -0.08468563  |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 60.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1386         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034712336 |\n",
      "|    clip_fraction        | 0.00303      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | 5.07e-05     |\n",
      "|    reward               | -1.8755319   |\n",
      "|    std                  | 0.817        |\n",
      "|    value_loss           | 21.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 61.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1386         |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038605437 |\n",
      "|    clip_fraction        | 0.0505       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | 1.8557519    |\n",
      "|    std                  | 0.808        |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 61.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027015964 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.81         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.000429    |\n",
      "|    reward               | -2.0666869   |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 16.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 61.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023544861 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3            |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.000658    |\n",
      "|    reward               | 0.2117905    |\n",
      "|    std                  | 0.831        |\n",
      "|    value_loss           | 19.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 62.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036298868 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.93         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.000758    |\n",
      "|    reward               | -0.91965955  |\n",
      "|    std                  | 0.841        |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 63.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043671723 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.4         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000383    |\n",
      "|    reward               | 0.86964023   |\n",
      "|    std                  | 0.844        |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 63.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004160109 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.35         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | 5.43e-05     |\n",
      "|    reward               | -1.4057631   |\n",
      "|    std                  | 0.845        |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 64.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002261199 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.000792   |\n",
      "|    reward               | 1.3879912   |\n",
      "|    std                  | 0.843       |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 64.6          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1385          |\n",
      "|    iterations           | 100           |\n",
      "|    time_elapsed         | 147           |\n",
      "|    total_timesteps      | 204800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030489545 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.26         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 10.6          |\n",
      "|    n_updates            | 990           |\n",
      "|    policy_gradient_loss | 6.93e-06      |\n",
      "|    reward               | -1.1019231    |\n",
      "|    std                  | 0.854         |\n",
      "|    value_loss           | 22.4          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 65.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003746918 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.98        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00066    |\n",
      "|    reward               | -0.5561453  |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 23.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 66           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022426024 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | 0.9652864    |\n",
      "|    std                  | 0.851        |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 66            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1385          |\n",
      "|    iterations           | 103           |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 210944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054716074 |\n",
      "|    clip_fraction        | 0.00601       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.26         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.9          |\n",
      "|    n_updates            | 1020          |\n",
      "|    policy_gradient_loss | 0.000268      |\n",
      "|    reward               | 0.3495333     |\n",
      "|    std                  | 0.849         |\n",
      "|    value_loss           | 23.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 66           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005683169  |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.46         |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    reward               | -0.035960224 |\n",
      "|    std                  | 0.848        |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 66           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011952122 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.8         |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00076     |\n",
      "|    reward               | -0.18891808  |\n",
      "|    std                  | 0.856        |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 66.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1384         |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 156          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027726348 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.64         |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.000196    |\n",
      "|    reward               | 0.2913672    |\n",
      "|    std                  | 0.849        |\n",
      "|    value_loss           | 23.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 66.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1384        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004355705 |\n",
      "|    clip_fraction        | 0.0335      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | -1.4090967  |\n",
      "|    std                  | 0.844       |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 66.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1385          |\n",
      "|    iterations           | 108           |\n",
      "|    time_elapsed         | 159           |\n",
      "|    total_timesteps      | 221184        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044032346 |\n",
      "|    clip_fraction        | 0.0261        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.24         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.7          |\n",
      "|    n_updates            | 1070          |\n",
      "|    policy_gradient_loss | -0.00184      |\n",
      "|    reward               | -0.4034234    |\n",
      "|    std                  | 0.836         |\n",
      "|    value_loss           | 22.7          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 66.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1385          |\n",
      "|    iterations           | 109           |\n",
      "|    time_elapsed         | 161           |\n",
      "|    total_timesteps      | 223232        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019350852 |\n",
      "|    clip_fraction        | 0.00337       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.24         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 16.8          |\n",
      "|    n_updates            | 1080          |\n",
      "|    policy_gradient_loss | 0.000109      |\n",
      "|    reward               | -0.103818536  |\n",
      "|    std                  | 0.831         |\n",
      "|    value_loss           | 25.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 66.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023543646 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.3          |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    reward               | 0.19342452   |\n",
      "|    std                  | 0.822        |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 66.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010090658 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.71         |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.000376    |\n",
      "|    reward               | 0.17003872   |\n",
      "|    std                  | 0.815        |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 66.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1384         |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026342454 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.000909    |\n",
      "|    reward               | -0.30050725  |\n",
      "|    std                  | 0.821        |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 67.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1385         |\n",
      "|    iterations           | 113          |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 231424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037549508 |\n",
      "|    clip_fraction        | 0.00864      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | 0.000335     |\n",
      "|    reward               | -0.24635471  |\n",
      "|    std                  | 0.821        |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 67.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1383        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003183056 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | 0.000439    |\n",
      "|    reward               | 0.02588523  |\n",
      "|    std                  | 0.821       |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 67.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1382         |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002468776 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.000195    |\n",
      "|    reward               | 0.31109336   |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1380         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012714986 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | 0.000632     |\n",
      "|    reward               | 1.0152301    |\n",
      "|    std                  | 0.816        |\n",
      "|    value_loss           | 22.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1378         |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 173          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010253175 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.000225    |\n",
      "|    reward               | 0.35483968   |\n",
      "|    std                  | 0.815        |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 67.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1377         |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 175          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004344733 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.6         |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | 0.000358     |\n",
      "|    reward               | -1.2485728   |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 25.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 67.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1375         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028921743 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.38         |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.000426    |\n",
      "|    reward               | 0.37037852   |\n",
      "|    std                  | 0.829        |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 67.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1374         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019809292 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.5          |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | 0.000243     |\n",
      "|    reward               | 1.4527222    |\n",
      "|    std                  | 0.835        |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1372         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061182617 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.29         |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    reward               | 1.7283386    |\n",
      "|    std                  | 0.827        |\n",
      "|    value_loss           | 19.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1371         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032457663 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.63         |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.000805    |\n",
      "|    reward               | 0.5137605    |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1371         |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006432942 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.24         |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | 0.000386     |\n",
      "|    reward               | -1.3091197   |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 68.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1371        |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004474897 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.18        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    reward               | 0.11530712  |\n",
      "|    std                  | 0.822       |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 68.5          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1372          |\n",
      "|    iterations           | 125           |\n",
      "|    time_elapsed         | 186           |\n",
      "|    total_timesteps      | 256000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073285133 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 14.4          |\n",
      "|    n_updates            | 1240          |\n",
      "|    policy_gradient_loss | 0.000173      |\n",
      "|    reward               | 1.0927435     |\n",
      "|    std                  | 0.833         |\n",
      "|    value_loss           | 17.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1372         |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032410186 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.33         |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.00021     |\n",
      "|    reward               | -0.08154375  |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1371         |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 260096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046880227 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.000755    |\n",
      "|    reward               | 1.0108004    |\n",
      "|    std                  | 0.828        |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 68.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1371        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002743499 |\n",
      "|    clip_fraction        | 0.026       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    reward               | 0.8861982   |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1372         |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 264192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046902485 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.25         |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 0.81435245   |\n",
      "|    std                  | 0.821        |\n",
      "|    value_loss           | 20.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1372         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019106085 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.4         |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -0.000853    |\n",
      "|    reward               | 0.5172457    |\n",
      "|    std                  | 0.815        |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 68.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1370        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002102682 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.000568   |\n",
      "|    reward               | -0.9078433  |\n",
      "|    std                  | 0.803       |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 67.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1369        |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005820453 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.54        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -4.87e-05   |\n",
      "|    reward               | -0.26448473 |\n",
      "|    std                  | 0.799       |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 67.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010055753 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.6         |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.000795    |\n",
      "|    reward               | 0.13541262   |\n",
      "|    std                  | 0.809        |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 67.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042573004 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.61         |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    reward               | 0.07207227   |\n",
      "|    std                  | 0.812        |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 276480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063731484 |\n",
      "|    clip_fraction        | 0.039        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.4         |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | -0.089561224 |\n",
      "|    std                  | 0.814        |\n",
      "|    value_loss           | 23           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028820212 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.05         |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.000824    |\n",
      "|    reward               | 0.29962543   |\n",
      "|    std                  | 0.815        |\n",
      "|    value_loss           | 22.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 280576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.003214129  |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.000774    |\n",
      "|    reward               | -0.024570404 |\n",
      "|    std                  | 0.807        |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026871436 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.98         |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | 0.000161     |\n",
      "|    reward               | 0.76159286   |\n",
      "|    std                  | 0.802        |\n",
      "|    value_loss           | 23.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050625834 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.99         |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 1.8625726    |\n",
      "|    std                  | 0.807        |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 68.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043554446 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | 0.3891361    |\n",
      "|    std                  | 0.804        |\n",
      "|    value_loss           | 24.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 69           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 288768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010884138 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -5.99e-05    |\n",
      "|    reward               | 0.35947356   |\n",
      "|    std                  | 0.816        |\n",
      "|    value_loss           | 23.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 69.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1369         |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025615473 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.000102    |\n",
      "|    reward               | -0.017661475 |\n",
      "|    std                  | 0.82         |\n",
      "|    value_loss           | 23.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 69.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1369        |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003257688 |\n",
      "|    clip_fraction        | 0.00493     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.000822   |\n",
      "|    reward               | -0.16444804 |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 25          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 69.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004196871 |\n",
      "|    clip_fraction        | 0.0353      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.8         |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    reward               | 0.036432367 |\n",
      "|    std                  | 0.818       |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 69.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1368         |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016616248 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.000465    |\n",
      "|    reward               | 0.43685558   |\n",
      "|    std                  | 0.817        |\n",
      "|    value_loss           | 22.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 69.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1368         |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034025752 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.3         |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.000935    |\n",
      "|    reward               | 0.2966844    |\n",
      "|    std                  | 0.808        |\n",
      "|    value_loss           | 22.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 69.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1368         |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049712807 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.79         |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | -0.08258136  |\n",
      "|    std                  | 0.802        |\n",
      "|    value_loss           | 23.1         |\n",
      "------------------------------------------\n",
      "✅ 模型儲存於：E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_1.zip\n",
      "🧠 訓練群 2：['1101.TW', '1102.TW']\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 984         |\n",
      "|    ep_rew_mean     | -14.8       |\n",
      "| time/              |             |\n",
      "|    fps             | 2806        |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 0           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.16409145 |\n",
      "------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 936         |\n",
      "|    ep_rew_mean          | -17.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1851        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005134033 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.00386     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    reward               | 0.6560887   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.38        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 972          |\n",
      "|    ep_rew_mean          | -17.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1639         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063129338 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.00365      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    reward               | -0.124829575 |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 2.43         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 989          |\n",
      "|    ep_rew_mean          | -16.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1536         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032095986 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.000203    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.49         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    reward               | -0.21276744  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.42         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -16.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1497        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005416088 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | -0.00344    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.000666   |\n",
      "|    reward               | 0.040147994 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.86        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -16.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1468        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008382365 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.000905    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    reward               | -0.5715209  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.22        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 985          |\n",
      "|    ep_rew_mean          | -18          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1455         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042336965 |\n",
      "|    clip_fraction        | 0.0584       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | -0.00325     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    reward               | -0.2678049   |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 2.36         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 985         |\n",
      "|    ep_rew_mean          | -18         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1444        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005153483 |\n",
      "|    clip_fraction        | 0.0252      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.00383     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.37        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    reward               | -0.06629428 |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 961           |\n",
      "|    ep_rew_mean          | -19.4         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1423          |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 12            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005580499   |\n",
      "|    clip_fraction        | 0.0533        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.8          |\n",
      "|    explained_variance   | -0.00585      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.45          |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.00317      |\n",
      "|    reward               | -0.0044141104 |\n",
      "|    std                  | 0.985         |\n",
      "|    value_loss           | 2.72          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 968          |\n",
      "|    ep_rew_mean          | -18.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1416         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030656515 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.026        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | -1.4672221   |\n",
      "|    std                  | 0.98         |\n",
      "|    value_loss           | 2.69         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 956        |\n",
      "|    ep_rew_mean          | -19.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1411       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00235321 |\n",
      "|    clip_fraction        | 0.00542    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.8       |\n",
      "|    explained_variance   | 0.000249   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.09       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.000203  |\n",
      "|    reward               | 0.13466606 |\n",
      "|    std                  | 0.978      |\n",
      "|    value_loss           | 2.55       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 963         |\n",
      "|    ep_rew_mean          | -18.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003068321 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | -0.00908    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.944       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    reward               | -0.21099006 |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 2.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 969         |\n",
      "|    ep_rew_mean          | -18.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1373        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002722933 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | -0.00185    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    reward               | 0.032639965 |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 2.31        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 963          |\n",
      "|    ep_rew_mean          | -18.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1349         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046214717 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.000391     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | 0.50387126   |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 2.76         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 964         |\n",
      "|    ep_rew_mean          | -19         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1340        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004042895 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | -0.00204    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.000152   |\n",
      "|    reward               | -0.38025832 |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 2.1         |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 959         |\n",
      "|    ep_rew_mean          | -18.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1336        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006401725 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.00279     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 0.16492306  |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 955         |\n",
      "|    ep_rew_mean          | -18.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1324        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002830219 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.00225     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000328   |\n",
      "|    reward               | -0.2223539  |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 960          |\n",
      "|    ep_rew_mean          | -18.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018372276 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.0122       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | -0.5086846   |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 2.67         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 960           |\n",
      "|    ep_rew_mean          | -18.7         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1310          |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00064818934 |\n",
      "|    clip_fraction        | 0.00776       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.8          |\n",
      "|    explained_variance   | -0.0174       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.01          |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000571     |\n",
      "|    reward               | 0.17673457    |\n",
      "|    std                  | 0.986         |\n",
      "|    value_loss           | 2.08          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 964          |\n",
      "|    ep_rew_mean          | -18.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016584031 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | -0.00291     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | 0.000492     |\n",
      "|    reward               | 0.05264282   |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 968         |\n",
      "|    ep_rew_mean          | -17.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006271426 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.00269     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.965       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    reward               | -1.2429844  |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 2.07        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 964         |\n",
      "|    ep_rew_mean          | -17.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003676596 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | -0.00125    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.31        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.000984   |\n",
      "|    reward               | 0.31446162  |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 2.18        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 961          |\n",
      "|    ep_rew_mean          | -18.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1292         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016091068 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | -0.00397     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.16         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    reward               | 0.38260195   |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 2.6          |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 956          |\n",
      "|    ep_rew_mean          | -18.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1292         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005026931  |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.00126      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000724    |\n",
      "|    reward               | -0.083624765 |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 2.63         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 959         |\n",
      "|    ep_rew_mean          | -18.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004679228 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.00253     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.955       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    reward               | -0.5798039  |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 2.3         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 962          |\n",
      "|    ep_rew_mean          | -18.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1288         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018629783 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | -0.00104     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.942        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    reward               | -0.79210377  |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 2.37         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 963         |\n",
      "|    ep_rew_mean          | -18         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1282        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004507644 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.001       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    reward               | 0.829929    |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 2.21        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 966        |\n",
      "|    ep_rew_mean          | -18        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1279       |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0037705  |\n",
      "|    clip_fraction        | 0.0288     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.79      |\n",
      "|    explained_variance   | 0.000607   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.04       |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00219   |\n",
      "|    reward               | 0.63018304 |\n",
      "|    std                  | 0.97       |\n",
      "|    value_loss           | 2.41       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 965          |\n",
      "|    ep_rew_mean          | -18.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1278         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058318432 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | -0.00163     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.03         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    reward               | 0.31229305   |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 967          |\n",
      "|    ep_rew_mean          | -18          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1275         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049741063 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.00102      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.688        |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    reward               | -0.019104213 |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 970          |\n",
      "|    ep_rew_mean          | -18          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1270         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042353123 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | -0.000457    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.55         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    reward               | 0.10118492   |\n",
      "|    std                  | 0.974        |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 972          |\n",
      "|    ep_rew_mean          | -17.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1269         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036525857 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.000175     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.912        |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000839    |\n",
      "|    reward               | 0.19565214   |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 974          |\n",
      "|    ep_rew_mean          | -17.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1266         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053314427 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.704        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -0.26263753  |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 971          |\n",
      "|    ep_rew_mean          | -17.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1267         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058003026 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | -0.000132    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.995        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.67939395   |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 1.61         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 973          |\n",
      "|    ep_rew_mean          | -17.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1270         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021455311 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.00221      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.935        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | 0.09965317   |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 2.33         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 975          |\n",
      "|    ep_rew_mean          | -17.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1273         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050090696 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.000614     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.741        |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    reward               | 1.0550307    |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 1.43         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 973          |\n",
      "|    ep_rew_mean          | -17.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1275         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057614665 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | -0.00108     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.543        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    reward               | 0.055969693  |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 1.5          |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 973          |\n",
      "|    ep_rew_mean          | -18          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1275         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072771204 |\n",
      "|    clip_fraction        | 0.0675       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.00368      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.872        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    reward               | -0.15048736  |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 975         |\n",
      "|    ep_rew_mean          | -17.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1278        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004268768 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.00328     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.641       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.000769   |\n",
      "|    reward               | -0.2908862  |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 977          |\n",
      "|    ep_rew_mean          | -17.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1280         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007629107 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | 0.00263      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.509        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | 0.000456     |\n",
      "|    reward               | -0.58322906  |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 978         |\n",
      "|    ep_rew_mean          | -17.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1282        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004178594 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.00155     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.871       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    reward               | -0.7201106  |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 1.62        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 980          |\n",
      "|    ep_rew_mean          | -17.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1282         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040060673 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | -0.00354     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000951    |\n",
      "|    reward               | 0.22045232   |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 1.5          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 981          |\n",
      "|    ep_rew_mean          | -17.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1284         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053123883 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.000587     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1            |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 0.119047314  |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 1.71         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 982          |\n",
      "|    ep_rew_mean          | -17.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1286         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012349219 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | -0.000702    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.623        |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000286    |\n",
      "|    reward               | -0.8629061   |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 984          |\n",
      "|    ep_rew_mean          | -17.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1287         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008324685  |\n",
      "|    clip_fraction        | 0.0773       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.000644     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.575        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    reward               | -0.036211737 |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 985         |\n",
      "|    ep_rew_mean          | -17.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004954903 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.0014      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.66        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    reward               | 0.90470254  |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 986          |\n",
      "|    ep_rew_mean          | -16.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1289         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049673263 |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | -0.000292    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.564        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 0.21115144   |\n",
      "|    std                  | 0.967        |\n",
      "|    value_loss           | 1.37         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 987          |\n",
      "|    ep_rew_mean          | -16.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1290         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032607552 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.00103      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.464        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | -0.21020055  |\n",
      "|    std                  | 0.974        |\n",
      "|    value_loss           | 1.35         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 988          |\n",
      "|    ep_rew_mean          | -16.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1291         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018370732 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.79        |\n",
      "|    explained_variance   | -0.00131     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.551        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.000549    |\n",
      "|    reward               | -0.008240444 |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 992          |\n",
      "|    ep_rew_mean          | -16.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1291         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038757562 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | -0.000233    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.875        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    reward               | 0.33328086   |\n",
      "|    std                  | 0.974        |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 992         |\n",
      "|    ep_rew_mean          | -16.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1292        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004489729 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.741       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | 0.23176345  |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 992         |\n",
      "|    ep_rew_mean          | -16.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004337532 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 5.33e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.738       |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    reward               | -0.3639711  |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 992          |\n",
      "|    ep_rew_mean          | -16.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1292         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028900611 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.000526     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.519        |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    reward               | -0.34569946  |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 993          |\n",
      "|    ep_rew_mean          | -16.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1294         |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021736638 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.75        |\n",
      "|    explained_variance   | 8.9e-05      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.506        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.000735    |\n",
      "|    reward               | -0.04370369  |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 993          |\n",
      "|    ep_rew_mean          | -15.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1294         |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051567825 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.000443     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.44         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    reward               | 0.066802636  |\n",
      "|    std                  | 0.953        |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 997        |\n",
      "|    ep_rew_mean          | -15.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1295       |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 88         |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00576766 |\n",
      "|    clip_fraction        | 0.0366     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.74      |\n",
      "|    explained_variance   | 0.000271   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.485      |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.00246   |\n",
      "|    reward               | -0.0871863 |\n",
      "|    std                  | 0.953      |\n",
      "|    value_loss           | 1.3        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -15.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1295         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042070393 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | -0.000791    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.808        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | 0.6941194    |\n",
      "|    std                  | 0.955        |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -15.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1295         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048067058 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.00137      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.483        |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    reward               | 0.17080897   |\n",
      "|    std                  | 0.956        |\n",
      "|    value_loss           | 1.31         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -15.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005237681 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.00124     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.402       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | -0.22235024 |\n",
      "|    std                  | 0.947       |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -14.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035590273 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.488        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | 0.000116     |\n",
      "|    reward               | -0.14409092  |\n",
      "|    std                  | 0.952        |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -15.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047252555 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 5.58e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.635        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    reward               | -0.057711754 |\n",
      "|    std                  | 0.95         |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -15         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004372544 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.00232     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.527       |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    reward               | -0.13174774 |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -14.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005313402 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | -0.000483   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.759       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | 0.21191764  |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -14.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1300         |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007943694 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.000226     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.72         |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.000563    |\n",
      "|    reward               | -0.16372634  |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -13.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004347198 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.468       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    reward               | -0.1095038  |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -13.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045320834 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | -6.85e-05    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.594        |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.000921    |\n",
      "|    reward               | -0.22750022  |\n",
      "|    std                  | 0.952        |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -13.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041722404 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 2.06e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.693        |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | 0.4177277    |\n",
      "|    std                  | 0.949        |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -13.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020432065 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0.000454     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.503        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.000385    |\n",
      "|    reward               | 0.029402254  |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -13          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044533145 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.629        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 0.032035314  |\n",
      "|    std                  | 0.946        |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -13          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054667313 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.586        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    reward               | -0.317521    |\n",
      "|    std                  | 0.952        |\n",
      "|    value_loss           | 1.33         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -12.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010509697 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.000173     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.546        |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | 0.000364     |\n",
      "|    reward               | 0.008485273  |\n",
      "|    std                  | 0.955        |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -12.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003868293 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.717       |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    reward               | -0.08618317 |\n",
      "|    std                  | 0.952       |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -11.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030467797 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.000106     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.63         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | 0.26863593   |\n",
      "|    std                  | 0.949        |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.03e+03   |\n",
      "|    ep_rew_mean          | -11.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1304       |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 151552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00494935 |\n",
      "|    clip_fraction        | 0.019      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.72      |\n",
      "|    explained_variance   | -5.41e-05  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.535      |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.000772  |\n",
      "|    reward               | 0.615008   |\n",
      "|    std                  | 0.941      |\n",
      "|    value_loss           | 1.11       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -11.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039517204 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 4.51e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.704        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.000332    |\n",
      "|    reward               | -0.3363761   |\n",
      "|    std                  | 0.946        |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -11.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042315293 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.636        |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.000343    |\n",
      "|    reward               | 0.39915577   |\n",
      "|    std                  | 0.952        |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.03e+03   |\n",
      "|    ep_rew_mean          | -10.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1305       |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 157696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00549547 |\n",
      "|    clip_fraction        | 0.0194     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.74      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.608      |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.000727  |\n",
      "|    reward               | 0.23340338 |\n",
      "|    std                  | 0.949      |\n",
      "|    value_loss           | 1.28       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -10.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005835457 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.499       |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    reward               | -0.6825732  |\n",
      "|    std                  | 0.952       |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -10.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032598837 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.493        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | 5.4e-05      |\n",
      "|    reward               | 0.47137728   |\n",
      "|    std                  | 0.954        |\n",
      "|    value_loss           | 1.31         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -9.61        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032438631 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.75        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.482        |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.000501    |\n",
      "|    reward               | -0.08768944  |\n",
      "|    std                  | 0.959        |\n",
      "|    value_loss           | 1.16         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -9.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027941132 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.658        |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    reward               | -0.03276925  |\n",
      "|    std                  | 0.948        |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -9.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007777402 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.855       |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | -0.13717061 |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -8.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060336348 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.555        |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 0.32409498   |\n",
      "|    std                  | 0.954        |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -8.55        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024180657 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.683        |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000721    |\n",
      "|    reward               | 0.003984117  |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -8.32        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028726598 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.422        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    reward               | -0.24396287  |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -8.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032673473 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.671        |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.000402    |\n",
      "|    reward               | 0.13383317   |\n",
      "|    std                  | 0.947        |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.04e+03   |\n",
      "|    ep_rew_mean          | -7.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1299       |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 137        |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00361659 |\n",
      "|    clip_fraction        | 0.0282     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.73      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.778      |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.00211   |\n",
      "|    reward               | 0.5601969  |\n",
      "|    std                  | 0.951      |\n",
      "|    value_loss           | 1.18       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -7.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1297         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056389957 |\n",
      "|    clip_fraction        | 0.0459       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.58         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | -0.40820533  |\n",
      "|    std                  | 0.948        |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.85        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1296         |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026656506 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.637        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.000878    |\n",
      "|    reward               | -0.033424165 |\n",
      "|    std                  | 0.955        |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.54        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1294         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 142          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061561745 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.373        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 0.25788927   |\n",
      "|    std                  | 0.939        |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -6.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005312589 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.554       |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | 0.16492306  |\n",
      "|    std                  | 0.941       |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.83        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038032518 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.495        |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    reward               | -0.40627483  |\n",
      "|    std                  | 0.949        |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.65        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1291         |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047206967 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.477        |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 0.66821957   |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.56        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048533287 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.611        |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    reward               | -0.4222564   |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.36        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041832244 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.418        |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | -0.6319972   |\n",
      "|    std                  | 0.934        |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032592984 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.658        |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.000746    |\n",
      "|    reward               | -0.5245199   |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 1.08         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.98        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1294         |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029126029 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.515        |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    reward               | -0.41110778  |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1295         |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029747393 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.72        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.568        |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.000904    |\n",
      "|    reward               | 0.5893753    |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -4.52       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003021842 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.613       |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.000539   |\n",
      "|    reward               | 0.23045316  |\n",
      "|    std                  | 0.948       |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -4.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005027177 |\n",
      "|    clip_fraction        | 0.0322      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.519       |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    reward               | -0.07718982 |\n",
      "|    std                  | 0.94        |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.17        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1296         |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040674442 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.624        |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    reward               | -0.20622157  |\n",
      "|    std                  | 0.933        |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.94        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1296         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021939063 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.408        |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.000578    |\n",
      "|    reward               | 0.610165     |\n",
      "|    std                  | 0.93         |\n",
      "|    value_loss           | 1.07         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -3.66         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1297          |\n",
      "|    iterations           | 103           |\n",
      "|    time_elapsed         | 162           |\n",
      "|    total_timesteps      | 210944        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0030714427  |\n",
      "|    clip_fraction        | 0.0201        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.69         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.563         |\n",
      "|    n_updates            | 1020          |\n",
      "|    policy_gradient_loss | -0.00139      |\n",
      "|    reward               | -0.0051892274 |\n",
      "|    std                  | 0.935         |\n",
      "|    value_loss           | 1.27          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.38        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1297         |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029483386 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.744        |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.000845    |\n",
      "|    reward               | 0.5137879    |\n",
      "|    std                  | 0.935        |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1297         |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039570197 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.447        |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    reward               | 0.3283671    |\n",
      "|    std                  | 0.939        |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041550724 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.516        |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    reward               | -0.36989656  |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.66        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038993107 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.871        |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | -1.1017296   |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -2.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004076219 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.549       |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    reward               | -0.06093974 |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.17        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013517621 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.409        |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | 0.00018      |\n",
      "|    reward               | 0.31968597   |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 173          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058001536 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.71        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.435        |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    reward               | 0.05037179   |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.99        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036071106 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.804        |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    reward               | -0.1570787   |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -1.51         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1300          |\n",
      "|    iterations           | 112           |\n",
      "|    time_elapsed         | 176           |\n",
      "|    total_timesteps      | 229376        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051494106 |\n",
      "|    clip_fraction        | 0.00469       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.7          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.667         |\n",
      "|    n_updates            | 1110          |\n",
      "|    policy_gradient_loss | 0.000472      |\n",
      "|    reward               | 0.35147956    |\n",
      "|    std                  | 0.937         |\n",
      "|    value_loss           | 1.15          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1300        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002478729 |\n",
      "|    clip_fraction        | 0.00103     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.753       |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | 0.000602    |\n",
      "|    reward               | 0.2497309   |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 114          |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057336446 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.35         |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    reward               | 0.25316346   |\n",
      "|    std                  | 0.93         |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036051418 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.699        |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 0.34988442   |\n",
      "|    std                  | 0.921        |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.946       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033745593 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.67        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.474        |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | -0.024431217 |\n",
      "|    std                  | 0.923        |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -0.809      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004662955 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.566       |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00173    |\n",
      "|    reward               | 0.03231875  |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.655       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031639687 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.652        |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000836    |\n",
      "|    reward               | 0.39342546   |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.582       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 187          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029491195 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.505        |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.000396    |\n",
      "|    reward               | -0.23735239  |\n",
      "|    std                  | 0.936        |\n",
      "|    value_loss           | 1.16         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -0.463        |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1303          |\n",
      "|    iterations           | 120           |\n",
      "|    time_elapsed         | 188           |\n",
      "|    total_timesteps      | 245760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095312524 |\n",
      "|    clip_fraction        | 0.00723       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.7          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.303         |\n",
      "|    n_updates            | 1190          |\n",
      "|    policy_gradient_loss | 0.000453      |\n",
      "|    reward               | -0.22973752   |\n",
      "|    std                  | 0.935         |\n",
      "|    value_loss           | 1.19          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.249       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038948779 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.487        |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.00075     |\n",
      "|    reward               | 0.5534894    |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.124       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042159073 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.459        |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | -0.08222757  |\n",
      "|    std                  | 0.936        |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -0.0464     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004271795 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.433       |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    reward               | -0.11802849 |\n",
      "|    std                  | 0.932       |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.00252      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046699913 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.445        |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    reward               | -0.23535018  |\n",
      "|    std                  | 0.93         |\n",
      "|    value_loss           | 1.08         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.0693       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026742748 |\n",
      "|    clip_fraction        | 0.00796      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.535        |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.000333    |\n",
      "|    reward               | -0.39930627  |\n",
      "|    std                  | 0.934        |\n",
      "|    value_loss           | 1.18         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.0587       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016868659 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.662        |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | 0.000191     |\n",
      "|    reward               | -0.6566397   |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.132        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 260096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073942617 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.475        |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    reward               | -0.6282953   |\n",
      "|    std                  | 0.93         |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.131       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00303804  |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.82        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    reward               | -0.24324134 |\n",
      "|    std                  | 0.929       |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.163       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007453901 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.847       |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | -0.2786294  |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.252       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004152476 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.552       |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.000716   |\n",
      "|    reward               | 0.24904153  |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.341       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005053103 |\n",
      "|    clip_fraction        | 0.0343      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.701       |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | 0.26699397  |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.382        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 132          |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021016344 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.357        |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | -0.000189    |\n",
      "|    reward               | -0.10448229  |\n",
      "|    std                  | 0.934        |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004951251 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.56        |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | 0.6283498   |\n",
      "|    std                  | 0.938       |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.463       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004870915 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.384       |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | 0.49371657  |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.467        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1296         |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 276480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050795344 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.409        |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    reward               | 0.47358593   |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.495        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1295         |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001982512  |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.534        |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.000474    |\n",
      "|    reward               | -0.047478482 |\n",
      "|    std                  | 0.941        |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.673        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1294         |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 280576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050366987 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.322        |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | 0.56140333   |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.767        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032494524 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.67        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.566        |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.000495    |\n",
      "|    reward               | -0.13210684  |\n",
      "|    std                  | 0.925        |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.757        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037735023 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.67        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.534        |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | 0.12311268   |\n",
      "|    std                  | 0.925        |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.867        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1292         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013380442 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.423        |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00071     |\n",
      "|    reward               | -0.56606835  |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 1.26         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.887        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1291         |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 223          |\n",
      "|    total_timesteps      | 288768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028833337 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.951        |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.000156    |\n",
      "|    reward               | -0.51530665  |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.856        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1290         |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 225          |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015327053 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.479        |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    reward               | 0.32173136   |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.879        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1289         |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043746554 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.632        |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 1.1524025    |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.956        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1289         |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043964977 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.591        |\n",
      "|    n_updates            | 1430         |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | 0.006228838  |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 1.28         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.93         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1289         |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073310486 |\n",
      "|    clip_fraction        | 0.0518       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.384        |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    reward               | 0.17828183   |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.923        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1289         |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026917297 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.633        |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.000717    |\n",
      "|    reward               | -0.75542617  |\n",
      "|    std                  | 0.95         |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 1.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003052573 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.707       |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    reward               | 0.47058648  |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "✅ 模型儲存於：E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_2.zip\n",
      "🧠 訓練群 3：['1722.TW']\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | -13.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 2999     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "| train/             |          |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -10.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1785         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050875493 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -2.43e-05    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00053     |\n",
      "|    reward               | -0.2818784   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.41         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -7.73        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1625         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021566157 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 3.64e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | 0.28871188   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.63         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -9.34        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1560         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003472636 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -0.00572     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.85         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -2.15e-06    |\n",
      "|    reward               | 0.88739884   |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 2.32         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -10.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005436858 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -0.000252   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.51        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | 0.091891535 |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 2.87        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -8.65        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1479         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024489616 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.00412      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.936        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    reward               | -0.14218812  |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 2.07         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -7.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1452        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004544503 |\n",
      "|    clip_fraction        | 0.0264      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    reward               | 0.050705146 |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -7.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1445        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001694602 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.000357    |\n",
      "|    reward               | -0.13583322 |\n",
      "|    std                  | 0.972       |\n",
      "|    value_loss           | 2.17        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -7.81        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1426         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031138891 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.921        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000961    |\n",
      "|    reward               | -0.09078747  |\n",
      "|    std                  | 0.952        |\n",
      "|    value_loss           | 2.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -7.72        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1424         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048633255 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | -0.03629878  |\n",
      "|    std                  | 0.95         |\n",
      "|    value_loss           | 2.83         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -7.86        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1410         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036160515 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.3          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.953        |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1409         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012412319 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | -6.91e-06    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.976        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000105    |\n",
      "|    reward               | -0.69078517  |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 2.11         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1407         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022349018 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    reward               | 1.4442716    |\n",
      "|    std                  | 0.957        |\n",
      "|    value_loss           | 2.39         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.47        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1401         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012268587 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.569        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | 3.85e-05     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.956        |\n",
      "|    value_loss           | 1.81         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.27        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1397         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.011473e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.916        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | 0.000104     |\n",
      "|    reward               | 0.4083685    |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 2.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.39        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1397         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020556226 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000654    |\n",
      "|    reward               | 1.88786      |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 1.97         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.64        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1391         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025422536 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.749        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00077     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.96         |\n",
      "|    value_loss           | 2.25         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -4.14         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1390          |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 26            |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019318998 |\n",
      "|    clip_fraction        | 0.00083       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.38         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.51          |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | 0.00031       |\n",
      "|    reward               | -0.46240574   |\n",
      "|    std                  | 0.968         |\n",
      "|    value_loss           | 2.09          |\n",
      "-------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -4.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005459658 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    reward               | 0.37319216  |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.03e+03      |\n",
      "|    ep_rew_mean          | -3.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1385          |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00082008395 |\n",
      "|    clip_fraction        | 0.00234       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.36         |\n",
      "|    explained_variance   | 0.000137      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.36          |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000749     |\n",
      "|    reward               | 0.027187873   |\n",
      "|    std                  | 0.93          |\n",
      "|    value_loss           | 3.08          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -2.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1371        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0058701   |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    reward               | -0.21079955 |\n",
      "|    std                  | 0.915       |\n",
      "|    value_loss           | 2.94        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -2.83        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1366         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032137544 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    reward               | 0.35582778   |\n",
      "|    std                  | 0.906        |\n",
      "|    value_loss           | 3.5          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.03e+03   |\n",
      "|    ep_rew_mean          | -2.26      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1367       |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00424184 |\n",
      "|    clip_fraction        | 0.0221     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.935      |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.00217   |\n",
      "|    reward               | -1.3151481 |\n",
      "|    std                  | 0.896      |\n",
      "|    value_loss           | 3.21       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -1.82        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1367         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028209658 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.14         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00067     |\n",
      "|    reward               | -1.7178124   |\n",
      "|    std                  | 0.889        |\n",
      "|    value_loss           | 3.43         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -1.38        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033991663 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.2          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000769    |\n",
      "|    reward               | -2.276971    |\n",
      "|    std                  | 0.885        |\n",
      "|    value_loss           | 3.52         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -0.994       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1360         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043935226 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.25         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.000993    |\n",
      "|    reward               | -0.18097205  |\n",
      "|    std                  | 0.883        |\n",
      "|    value_loss           | 3.3          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -0.638       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1359         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010391588 |\n",
      "|    clip_fraction        | 0.00469      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000571    |\n",
      "|    reward               | 0.6761459    |\n",
      "|    std                  | 0.872        |\n",
      "|    value_loss           | 3.4          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -0.282      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004259186 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.55        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    reward               | -1.4744399  |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 4.13        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.03e+03   |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1360       |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00492613 |\n",
      "|    clip_fraction        | 0.0237     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.86       |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.00201   |\n",
      "|    reward               | -0.8489716 |\n",
      "|    std                  | 0.873      |\n",
      "|    value_loss           | 3.96       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 0.698        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1359         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030633286 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000107    |\n",
      "|    reward               | -0.17652084  |\n",
      "|    std                  | 0.873        |\n",
      "|    value_loss           | 3.83         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.03e+03   |\n",
      "|    ep_rew_mean          | 1.27       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1360       |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00236952 |\n",
      "|    clip_fraction        | 0.00313    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.55       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.000142  |\n",
      "|    reward               | 1.2916938  |\n",
      "|    std                  | 0.865      |\n",
      "|    value_loss           | 4          |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 1.7           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1359          |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 48            |\n",
      "|    total_timesteps      | 65536         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0036535226  |\n",
      "|    clip_fraction        | 0.00361       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.27         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.75          |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.000222     |\n",
      "|    reward               | -0.0073760003 |\n",
      "|    std                  | 0.861         |\n",
      "|    value_loss           | 4.2           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.07         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1351         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033190572 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2            |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | 0.5776029    |\n",
      "|    std                  | 0.867        |\n",
      "|    value_loss           | 4.15         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.67         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1348         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046825414 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.41         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    reward               | 0.39407313   |\n",
      "|    std                  | 0.863        |\n",
      "|    value_loss           | 3.97         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 3.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1342        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004756901 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.000269   |\n",
      "|    reward               | -0.43001485 |\n",
      "|    std                  | 0.865       |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 3.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1337        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002124768 |\n",
      "|    clip_fraction        | 0.00273     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00041    |\n",
      "|    reward               | -0.4334027  |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 4.07        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.12         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1334         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049525285 |\n",
      "|    clip_fraction        | 0.0602       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.85         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | -0.44820696  |\n",
      "|    std                  | 0.858        |\n",
      "|    value_loss           | 4.04         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.56         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032343431 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.25         |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.000726    |\n",
      "|    reward               | 0.55603004   |\n",
      "|    std                  | 0.86         |\n",
      "|    value_loss           | 4.16         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.98         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1328         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038078788 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.69         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000314    |\n",
      "|    reward               | -0.5657977   |\n",
      "|    std                  | 0.856        |\n",
      "|    value_loss           | 3.87         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1326         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043057473 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.26         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -0.18430638  |\n",
      "|    std                  | 0.851        |\n",
      "|    value_loss           | 4.04         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.75         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1320         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028276697 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.84         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -9.38e-05    |\n",
      "|    reward               | -0.19835913  |\n",
      "|    std                  | 0.852        |\n",
      "|    value_loss           | 3.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.84         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1319         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043032253 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.03         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000981    |\n",
      "|    reward               | 0.8432668    |\n",
      "|    std                  | 0.85         |\n",
      "|    value_loss           | 4.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 6.14         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010848816 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.03         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -6.04e-05    |\n",
      "|    reward               | -0.42177647  |\n",
      "|    std                  | 0.843        |\n",
      "|    value_loss           | 4            |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 6.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003777459 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    reward               | 0.33757484  |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 3.96        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 6.8          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035207833 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.03         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | -0.47843128  |\n",
      "|    std                  | 0.829        |\n",
      "|    value_loss           | 3.94         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 7.17         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022705798 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.39         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | -0.051706724 |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 3.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 7.52         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.869417e-05 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.19         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | 0.000521     |\n",
      "|    reward               | 0.4067205    |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 3.86         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 7.8          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015923553 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.26         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00056     |\n",
      "|    reward               | -0.3734286   |\n",
      "|    std                  | 0.822        |\n",
      "|    value_loss           | 4.06         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 8.12          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1302          |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 77            |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096813514 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.22         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.81          |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | 0.000421      |\n",
      "|    reward               | 0.24980494    |\n",
      "|    std                  | 0.823         |\n",
      "|    value_loss           | 4.02          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 8.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020533148 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.89         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.000642    |\n",
      "|    reward               | -0.059340306 |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 4.1          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 8.64         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034273881 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.64         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | -0.12367715  |\n",
      "|    std                  | 0.837        |\n",
      "|    value_loss           | 4.05         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 9.4          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026970834 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | 0.000119     |\n",
      "|    reward               | -1.7271444   |\n",
      "|    std                  | 0.837        |\n",
      "|    value_loss           | 3.87         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 9.7          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1294         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016291265 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.91         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.000148    |\n",
      "|    reward               | -1.8729295   |\n",
      "|    std                  | 0.841        |\n",
      "|    value_loss           | 4.07         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 10.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049127555 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    reward               | 1.2684132    |\n",
      "|    std                  | 0.837        |\n",
      "|    value_loss           | 3.83         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 11           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029585217 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.7          |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    reward               | -0.27654725  |\n",
      "|    std                  | 0.848        |\n",
      "|    value_loss           | 3.78         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 11.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1291          |\n",
      "|    iterations           | 56            |\n",
      "|    time_elapsed         | 88            |\n",
      "|    total_timesteps      | 114688        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019255318 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.25         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.23          |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | 0.000141      |\n",
      "|    reward               | -0.51958287   |\n",
      "|    std                  | 0.846         |\n",
      "|    value_loss           | 3.85          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 12.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1291         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028083923 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | 8.7e-05      |\n",
      "|    reward               | -1.4557174   |\n",
      "|    std                  | 0.844        |\n",
      "|    value_loss           | 3.9          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 12.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1290          |\n",
      "|    iterations           | 58            |\n",
      "|    time_elapsed         | 92            |\n",
      "|    total_timesteps      | 118784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012816224 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.25         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.94          |\n",
      "|    n_updates            | 570           |\n",
      "|    policy_gradient_loss | -1.11e-05     |\n",
      "|    reward               | 0.6730312     |\n",
      "|    std                  | 0.852         |\n",
      "|    value_loss           | 3.91          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 13.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1290         |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 93           |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065002916 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.738        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    reward               | -0.22240223  |\n",
      "|    std                  | 0.847        |\n",
      "|    value_loss           | 3.44         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1291        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003644751 |\n",
      "|    clip_fraction        | 0.0198      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.000862   |\n",
      "|    reward               | 0.09478825  |\n",
      "|    std                  | 0.846       |\n",
      "|    value_loss           | 3.95        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 14.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051434203 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.27         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    reward               | -0.08884835  |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 4.29         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 14.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1294         |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032312663 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.32         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.000339    |\n",
      "|    reward               | 0.22306353   |\n",
      "|    std                  | 0.844        |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 15.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1295         |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011859905 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.84         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.00052     |\n",
      "|    reward               | -0.40642     |\n",
      "|    std                  | 0.84         |\n",
      "|    value_loss           | 3.93         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 15.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004115983 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | -0.48102608 |\n",
      "|    std                  | 0.829       |\n",
      "|    value_loss           | 4.19        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 16.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027601244 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.22         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.000757    |\n",
      "|    reward               | -0.26460752  |\n",
      "|    std                  | 0.82         |\n",
      "|    value_loss           | 4.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 16.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004890632 |\n",
      "|    clip_fraction        | 0.00166      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.000296    |\n",
      "|    reward               | 0.504291     |\n",
      "|    std                  | 0.84         |\n",
      "|    value_loss           | 3.94         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 16.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1300         |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018493916 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.000577    |\n",
      "|    reward               | -0.15538944  |\n",
      "|    std                  | 0.849        |\n",
      "|    value_loss           | 3.96         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 17.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046866806 |\n",
      "|    clip_fraction        | 0.0698       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.73         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    reward               | 0.38802925   |\n",
      "|    std                  | 0.849        |\n",
      "|    value_loss           | 4.22         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 18           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066369567 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.27         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    reward               | 0.057688974  |\n",
      "|    std                  | 0.844        |\n",
      "|    value_loss           | 3.75         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 17.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005792011 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.88        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | -0.40975428 |\n",
      "|    std                  | 0.841       |\n",
      "|    value_loss           | 4.07        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 18           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033423302 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.29         |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00058     |\n",
      "|    reward               | 0.2806237    |\n",
      "|    std                  | 0.846        |\n",
      "|    value_loss           | 4.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 18.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015097461 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.42         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.000391    |\n",
      "|    reward               | -0.084944054 |\n",
      "|    std                  | 0.85         |\n",
      "|    value_loss           | 4.15         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 18.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017938096 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.14         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.000136    |\n",
      "|    reward               | 0.17309971   |\n",
      "|    std                  | 0.852        |\n",
      "|    value_loss           | 4.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 19           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012885805 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.43         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | 0.000208     |\n",
      "|    reward               | 0.33462247   |\n",
      "|    std                  | 0.853        |\n",
      "|    value_loss           | 4            |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 19.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000948326 |\n",
      "|    clip_fraction        | 0.0064      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.000295   |\n",
      "|    reward               | 0.15601757  |\n",
      "|    std                  | 0.843       |\n",
      "|    value_loss           | 4.11        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 19.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031401138 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.65         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.000529    |\n",
      "|    reward               | -0.40829575  |\n",
      "|    std                  | 0.833        |\n",
      "|    value_loss           | 3.87         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 19.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019453588 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.34         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | 5.72e-05     |\n",
      "|    reward               | 0.4474169    |\n",
      "|    std                  | 0.831        |\n",
      "|    value_loss           | 4.22         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 19.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033589192 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.04         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.000654    |\n",
      "|    reward               | 0.600931     |\n",
      "|    std                  | 0.827        |\n",
      "|    value_loss           | 4.05         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 19.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066426764 |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.66         |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 0.38806012   |\n",
      "|    std                  | 0.832        |\n",
      "|    value_loss           | 3.73         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013808133 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.34         |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | 0.000188     |\n",
      "|    reward               | -0.41849956  |\n",
      "|    std                  | 0.831        |\n",
      "|    value_loss           | 3.84         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021922556 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.13         |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    reward               | -0.34555504  |\n",
      "|    std                  | 0.83         |\n",
      "|    value_loss           | 3.5          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040415954 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | -0.27484536  |\n",
      "|    std                  | 0.828        |\n",
      "|    value_loss           | 3.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008863538 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.46         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | 0.000266     |\n",
      "|    reward               | 0.06980421   |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 3.69         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057785064 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.44         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000416    |\n",
      "|    reward               | 1.4353887    |\n",
      "|    std                  | 0.828        |\n",
      "|    value_loss           | 3.59         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020012106 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.04         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    reward               | 0.39396128   |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 3.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015511155 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.16         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.000353    |\n",
      "|    reward               | -0.041281298 |\n",
      "|    std                  | 0.816        |\n",
      "|    value_loss           | 3.88         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 20.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002928714 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.83        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    reward               | 0.46706903  |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 4.04        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003165514 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.68         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | 0.000379     |\n",
      "|    reward               | 0.6079481    |\n",
      "|    std                  | 0.837        |\n",
      "|    value_loss           | 3.79         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023827786 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.65         |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -2.85e-06    |\n",
      "|    reward               | 0.19752443   |\n",
      "|    std                  | 0.844        |\n",
      "|    value_loss           | 4.05         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030525047 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.24         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | 8.77e-05     |\n",
      "|    reward               | 0.9177717    |\n",
      "|    std                  | 0.842        |\n",
      "|    value_loss           | 4.22         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1318         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017560954 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.68         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.000405    |\n",
      "|    reward               | -0.23167337  |\n",
      "|    std                  | 0.84         |\n",
      "|    value_loss           | 3.91         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 20.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003098019 |\n",
      "|    clip_fraction        | 0.00835     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.33        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00035    |\n",
      "|    reward               | -0.08677134 |\n",
      "|    std                  | 0.843       |\n",
      "|    value_loss           | 4.13        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1319         |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024494831 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.9          |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    reward               | 0.06464298   |\n",
      "|    std                  | 0.843        |\n",
      "|    value_loss           | 3.97         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1320         |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012794938 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.03         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.000596    |\n",
      "|    reward               | -0.5463039   |\n",
      "|    std                  | 0.83         |\n",
      "|    value_loss           | 3.83         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1321         |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025126985 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.3          |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.000283    |\n",
      "|    reward               | 0.8767737    |\n",
      "|    std                  | 0.826        |\n",
      "|    value_loss           | 4.2          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 20.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1321        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004807873 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.12        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    reward               | 0.45386204  |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 4.03        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1321         |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018327058 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.63         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.000521    |\n",
      "|    reward               | 0.59448683   |\n",
      "|    std                  | 0.818        |\n",
      "|    value_loss           | 4.12         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1322         |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023728726 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.000683    |\n",
      "|    reward               | -0.016288877 |\n",
      "|    std                  | 0.818        |\n",
      "|    value_loss           | 4.15         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 20.9          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1322          |\n",
      "|    iterations           | 99            |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 202752        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00075281155 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.05          |\n",
      "|    n_updates            | 980           |\n",
      "|    policy_gradient_loss | -7.19e-05     |\n",
      "|    reward               | 0.89313823    |\n",
      "|    std                  | 0.831         |\n",
      "|    value_loss           | 4.03          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 20.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1323        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002532443 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.03        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00058    |\n",
      "|    reward               | 0.6598321   |\n",
      "|    std                  | 0.828       |\n",
      "|    value_loss           | 4.09        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1323         |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 156          |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002047001 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.32         |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | 9.25e-05     |\n",
      "|    reward               | -0.27229294  |\n",
      "|    std                  | 0.821        |\n",
      "|    value_loss           | 3.74         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 20.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1324          |\n",
      "|    iterations           | 102           |\n",
      "|    time_elapsed         | 157           |\n",
      "|    total_timesteps      | 208896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034544535 |\n",
      "|    clip_fraction        | 0.00522       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.22         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.46          |\n",
      "|    n_updates            | 1010          |\n",
      "|    policy_gradient_loss | 0.000286      |\n",
      "|    reward               | 0.38703814    |\n",
      "|    std                  | 0.817         |\n",
      "|    value_loss           | 3.97          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1324         |\n",
      "|    iterations           | 103          |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 210944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014995034 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.69         |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -4.14e-05    |\n",
      "|    reward               | 0.69906783   |\n",
      "|    std                  | 0.826        |\n",
      "|    value_loss           | 4.2          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 20.7          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1323          |\n",
      "|    iterations           | 104           |\n",
      "|    time_elapsed         | 160           |\n",
      "|    total_timesteps      | 212992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047407698 |\n",
      "|    clip_fraction        | 0.00737       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.99          |\n",
      "|    n_updates            | 1030          |\n",
      "|    policy_gradient_loss | -0.000388     |\n",
      "|    reward               | -0.07559464   |\n",
      "|    std                  | 0.835         |\n",
      "|    value_loss           | 4.01          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 20.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1322        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005449729 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | 0.2510315   |\n",
      "|    std                  | 0.838       |\n",
      "|    value_loss           | 4.25        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1320         |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034648175 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.27         |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.000799    |\n",
      "|    reward               | -0.2877407   |\n",
      "|    std                  | 0.834        |\n",
      "|    value_loss           | 4.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1320         |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039678426 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.63         |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.000613    |\n",
      "|    reward               | 0.3256603    |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 3.88         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 20.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1319        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002805926 |\n",
      "|    clip_fraction        | 0.00801     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.68        |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.000619   |\n",
      "|    reward               | 0.10439348  |\n",
      "|    std                  | 0.837       |\n",
      "|    value_loss           | 4.14        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 20.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1319         |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071757534 |\n",
      "|    clip_fraction        | 0.042        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    reward               | 0.6954038    |\n",
      "|    std                  | 0.84         |\n",
      "|    value_loss           | 3.97         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1319         |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032170964 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.00033     |\n",
      "|    reward               | -1.7041589   |\n",
      "|    std                  | 0.836        |\n",
      "|    value_loss           | 3.62         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1319         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046989783 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    reward               | 0.99882406   |\n",
      "|    std                  | 0.835        |\n",
      "|    value_loss           | 4.07         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1320         |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 173          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020905011 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | 0.000177     |\n",
      "|    reward               | -3.066196    |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 3.81         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 21.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1321        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006465159 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.14        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | -0.6302312  |\n",
      "|    std                  | 0.837       |\n",
      "|    value_loss           | 3.88        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 21.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1321          |\n",
      "|    iterations           | 114           |\n",
      "|    time_elapsed         | 176           |\n",
      "|    total_timesteps      | 233472        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028126177 |\n",
      "|    clip_fraction        | 0.00161       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.24         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.17          |\n",
      "|    n_updates            | 1130          |\n",
      "|    policy_gradient_loss | 0.00019       |\n",
      "|    reward               | 0.8273359     |\n",
      "|    std                  | 0.836         |\n",
      "|    value_loss           | 4.15          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1322         |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 178          |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021211146 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.46         |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -2.87e-05    |\n",
      "|    reward               | -2.7327504   |\n",
      "|    std                  | 0.832        |\n",
      "|    value_loss           | 4.17         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1322         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054446626 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    reward               | -0.010916092 |\n",
      "|    std                  | 0.829        |\n",
      "|    value_loss           | 3.72         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 21.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1323          |\n",
      "|    iterations           | 117           |\n",
      "|    time_elapsed         | 181           |\n",
      "|    total_timesteps      | 239616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00054993713 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.68          |\n",
      "|    n_updates            | 1160          |\n",
      "|    policy_gradient_loss | 0.000302      |\n",
      "|    reward               | -0.32872215   |\n",
      "|    std                  | 0.83          |\n",
      "|    value_loss           | 3.6           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1323         |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033267464 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    reward               | -1.5708791   |\n",
      "|    std                  | 0.833        |\n",
      "|    value_loss           | 4.22         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1324         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010796553 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.15         |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.00061     |\n",
      "|    reward               | 0.48363128   |\n",
      "|    std                  | 0.812        |\n",
      "|    value_loss           | 4.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1325         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047003557 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.21         |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.000943    |\n",
      "|    reward               | -0.22485577  |\n",
      "|    std                  | 0.804        |\n",
      "|    value_loss           | 4.08         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1325         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 186          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039202175 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.95         |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    reward               | 0.38787305   |\n",
      "|    std                  | 0.808        |\n",
      "|    value_loss           | 4.16         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1326         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.001548483  |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.66         |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    reward               | -0.114698686 |\n",
      "|    std                  | 0.795        |\n",
      "|    value_loss           | 4.12         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1326         |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010018516 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.89         |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.000648    |\n",
      "|    reward               | 0.057883073  |\n",
      "|    std                  | 0.79         |\n",
      "|    value_loss           | 4.19         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1327         |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033458015 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.29         |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.000419    |\n",
      "|    reward               | -0.5906934   |\n",
      "|    std                  | 0.787        |\n",
      "|    value_loss           | 4.16         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 21.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1327         |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032846513 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.94         |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | 0.000553     |\n",
      "|    reward               | -0.39958414  |\n",
      "|    std                  | 0.792        |\n",
      "|    value_loss           | 4.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1328         |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043316986 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    reward               | 0.5478245    |\n",
      "|    std                  | 0.795        |\n",
      "|    value_loss           | 3.96         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 22          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1328        |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003598445 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.2         |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    reward               | 0.807627    |\n",
      "|    std                  | 0.802       |\n",
      "|    value_loss           | 4.09        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 22            |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1329          |\n",
      "|    iterations           | 128           |\n",
      "|    time_elapsed         | 197           |\n",
      "|    total_timesteps      | 262144        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011375634 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.2          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.12          |\n",
      "|    n_updates            | 1270          |\n",
      "|    policy_gradient_loss | 0.000328      |\n",
      "|    reward               | 0.008081735   |\n",
      "|    std                  | 0.798         |\n",
      "|    value_loss           | 3.96          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 22          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1329        |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003393349 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.000454   |\n",
      "|    reward               | 0.01549137  |\n",
      "|    std                  | 0.795       |\n",
      "|    value_loss           | 4.17        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 22.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1330          |\n",
      "|    iterations           | 130           |\n",
      "|    time_elapsed         | 200           |\n",
      "|    total_timesteps      | 266240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010544472 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.19         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.97          |\n",
      "|    n_updates            | 1290          |\n",
      "|    policy_gradient_loss | 0.000172      |\n",
      "|    reward               | -0.3989245    |\n",
      "|    std                  | 0.795         |\n",
      "|    value_loss           | 4.13          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1330         |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 268288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010702214 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.82         |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.000234    |\n",
      "|    reward               | -0.2794116   |\n",
      "|    std                  | 0.786        |\n",
      "|    value_loss           | 4.23         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 22.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1330        |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004352568 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.86        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    reward               | 0.5415185   |\n",
      "|    std                  | 0.79        |\n",
      "|    value_loss           | 3.83        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022259336 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.89         |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -6.06e-05    |\n",
      "|    reward               | -0.93719596  |\n",
      "|    std                  | 0.786        |\n",
      "|    value_loss           | 3.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009002903 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.5          |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | 0.000174     |\n",
      "|    reward               | 0.18302777   |\n",
      "|    std                  | 0.793        |\n",
      "|    value_loss           | 4.15         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.04e+03   |\n",
      "|    ep_rew_mean          | 22.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1332       |\n",
      "|    iterations           | 135        |\n",
      "|    time_elapsed         | 207        |\n",
      "|    total_timesteps      | 276480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00418048 |\n",
      "|    clip_fraction        | 0.0196     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.18       |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | -0.00169   |\n",
      "|    reward               | -0.2973558 |\n",
      "|    std                  | 0.784      |\n",
      "|    value_loss           | 4.07       |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 22.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1332          |\n",
      "|    iterations           | 136           |\n",
      "|    time_elapsed         | 209           |\n",
      "|    total_timesteps      | 278528        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021796697 |\n",
      "|    clip_fraction        | 0.00879       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.17         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.53          |\n",
      "|    n_updates            | 1350          |\n",
      "|    policy_gradient_loss | -0.000358     |\n",
      "|    reward               | -0.17148972   |\n",
      "|    std                  | 0.783         |\n",
      "|    value_loss           | 4.33          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1332         |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 210          |\n",
      "|    total_timesteps      | 280576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048151603 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    reward               | 0.9871356    |\n",
      "|    std                  | 0.784        |\n",
      "|    value_loss           | 3.89         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042515174 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    reward               | -0.0941135   |\n",
      "|    std                  | 0.777        |\n",
      "|    value_loss           | 3.79         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043439823 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    reward               | 1.4032009    |\n",
      "|    std                  | 0.781        |\n",
      "|    value_loss           | 3.77         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 214          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012586602 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.31         |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.000608    |\n",
      "|    reward               | -0.42414898  |\n",
      "|    std                  | 0.768        |\n",
      "|    value_loss           | 3.87         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 22.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1334          |\n",
      "|    iterations           | 141           |\n",
      "|    time_elapsed         | 216           |\n",
      "|    total_timesteps      | 288768        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038391596 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.16         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 2.05          |\n",
      "|    n_updates            | 1400          |\n",
      "|    policy_gradient_loss | -5.29e-05     |\n",
      "|    reward               | 0.20228274    |\n",
      "|    std                  | 0.783         |\n",
      "|    value_loss           | 3.72          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1334         |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025431658 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.95         |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.000422    |\n",
      "|    reward               | -0.9751925   |\n",
      "|    std                  | 0.781        |\n",
      "|    value_loss           | 3.73         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027028753 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 0.016425973  |\n",
      "|    std                  | 0.78         |\n",
      "|    value_loss           | 4.07         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013986406 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 1430         |\n",
      "|    policy_gradient_loss | 5.55e-05     |\n",
      "|    reward               | -0.2912952   |\n",
      "|    std                  | 0.792        |\n",
      "|    value_loss           | 4.15         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1332         |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038063684 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.95         |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.000784    |\n",
      "|    reward               | 0.7457401    |\n",
      "|    std                  | 0.788        |\n",
      "|    value_loss           | 4.08         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1332         |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018648952 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.000427    |\n",
      "|    reward               | 0.047139797  |\n",
      "|    std                  | 0.779        |\n",
      "|    value_loss           | 3.72         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 22.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017509783 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.08         |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.000609    |\n",
      "|    reward               | -0.116484925 |\n",
      "|    std                  | 0.773        |\n",
      "|    value_loss           | 4.18         |\n",
      "------------------------------------------\n",
      "✅ 模型儲存於：E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_3.zip\n",
      "🧠 訓練群 4：['2002.TW']\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 1.04e+03     |\n",
      "|    ep_rew_mean     | -4.3         |\n",
      "| time/              |              |\n",
      "|    fps             | 2727         |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 0            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | 0.0011791363 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.69        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1677         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063019954 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.488        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.622        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -7.22        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1554         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004132786  |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.494        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    reward               | -0.042136285 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.953        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1512         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046232706 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.336        |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    reward               | -0.101617806 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.756        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -8.19        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1485         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015310447 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.245        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -1.19e-07    |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -7.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1472         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039206487 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.206        |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    reward               | 0.04858559   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.773        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -7           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1460         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042635873 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.626        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 0.027165271  |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.27        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1453         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001807895 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.561        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | 0.000383     |\n",
      "|    reward               | 0.2186756    |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 1.46         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -6.19         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1446          |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 12            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088496704 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.4          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.692         |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000243     |\n",
      "|    reward               | -0.3002707    |\n",
      "|    std                  | 0.978         |\n",
      "|    value_loss           | 1.13          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -6.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1439         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023662057 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.922        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | 0.000114     |\n",
      "|    reward               | 0.35441706   |\n",
      "|    std                  | 0.973        |\n",
      "|    value_loss           | 1.07         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.56       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1433        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004236645 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.409       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    reward               | -1.6864094  |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.52        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1430         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044041984 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.414        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    reward               | -0.058625843 |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 1.78         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -5.37        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1430         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021951115 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.746        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000102    |\n",
      "|    reward               | -0.360348    |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 0.942        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -5.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1414        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004249259 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.529       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    reward               | -0.05354072 |\n",
      "|    std                  | 0.949       |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4.92        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1406         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014478127 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.462        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000395    |\n",
      "|    reward               | 0.5073024    |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.04e+03   |\n",
      "|    ep_rew_mean          | -4.62      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1393       |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00201701 |\n",
      "|    clip_fraction        | 0.00674    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.38      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.928      |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.000269  |\n",
      "|    reward               | 0.42281953 |\n",
      "|    std                  | 0.967      |\n",
      "|    value_loss           | 1.24       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -4           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1386         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038422835 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.849        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | 0.10354531   |\n",
      "|    std                  | 0.971        |\n",
      "|    value_loss           | 1.67         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.65        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1377         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057268813 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.657        |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | -0.02438438  |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.41        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1370         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032644614 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 1.45         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.36        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1365         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019222386 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.609        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000646    |\n",
      "|    reward               | -0.014882059 |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.21        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1359         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043773195 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.28         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00158     |\n",
      "|    reward               | -0.4565941   |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 1.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1350         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023341398 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.487        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000316    |\n",
      "|    reward               | -0.15390845  |\n",
      "|    std                  | 0.957        |\n",
      "|    value_loss           | 1.5          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1349         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026328755 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.564        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.000268    |\n",
      "|    reward               | -0.034199134 |\n",
      "|    std                  | 0.951        |\n",
      "|    value_loss           | 1.16         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -3.74       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1342        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005719532 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.828       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    reward               | 0.66226155  |\n",
      "|    std                  | 0.957       |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.79        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1339         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014910479 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.81         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | 0.000222     |\n",
      "|    reward               | -0.16966486  |\n",
      "|    std                  | 0.968        |\n",
      "|    value_loss           | 1.74         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.53        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1337         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044548307 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.666        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | -0.06247778  |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045710057 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.433        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 0.028737964  |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -2.71         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1330          |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 43            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0069519607  |\n",
      "|    clip_fraction        | 0.0415        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.37         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.633         |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.0026       |\n",
      "|    reward               | 0.00071856973 |\n",
      "|    std                  | 0.95          |\n",
      "|    value_loss           | 1.9           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -2.49       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1327        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003158186 |\n",
      "|    clip_fraction        | 0.00796     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.817       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    reward               | 0.38073105  |\n",
      "|    std                  | 0.923       |\n",
      "|    value_loss           | 1.85        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.39        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1323         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028464566 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.761        |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000796    |\n",
      "|    reward               | 0.056853484  |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 2.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1320         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041854624 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.665        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | -0.16042764  |\n",
      "|    std                  | 0.912        |\n",
      "|    value_loss           | 1.89         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -2.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1318         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031500987 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    reward               | -0.56549287  |\n",
      "|    std                  | 0.9          |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.96        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013550638 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.643        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000135    |\n",
      "|    reward               | -0.3475749   |\n",
      "|    std                  | 0.914        |\n",
      "|    value_loss           | 1.54         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.67        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.853393e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.726        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | 0.000332     |\n",
      "|    reward               | -0.06771628  |\n",
      "|    std                  | 0.911        |\n",
      "|    value_loss           | 1.61         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047708796 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.536        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    reward               | -0.21891677  |\n",
      "|    std                  | 0.908        |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.57        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006830273 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.566        |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.000355    |\n",
      "|    reward               | 0.80482006   |\n",
      "|    std                  | 0.892        |\n",
      "|    value_loss           | 1.58         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.37       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1319        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002913204 |\n",
      "|    clip_fraction        | 0.00669     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.000179   |\n",
      "|    reward               | 0.06283761  |\n",
      "|    std                  | 0.891       |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.31       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1321        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005328119 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    reward               | 0.6895654   |\n",
      "|    std                  | 0.891       |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.32        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1321         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014182704 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.635        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.000544    |\n",
      "|    reward               | -0.15434022  |\n",
      "|    std                  | 0.905        |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1322        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004774544 |\n",
      "|    clip_fraction        | 0.0252      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00121    |\n",
      "|    reward               | 0.03102711  |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1323        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003181567 |\n",
      "|    clip_fraction        | 0.00928     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.878       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.000299   |\n",
      "|    reward               | 0.018622085 |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 1.75        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1325        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00663     |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.655       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    reward               | 0.104929596 |\n",
      "|    std                  | 0.891       |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -1.1          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1326          |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 66            |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045296163 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.3          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.817         |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | 0.00018       |\n",
      "|    reward               | -0.11126827   |\n",
      "|    std                  | 0.883         |\n",
      "|    value_loss           | 1.39          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.01        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1328         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033110934 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | 0.13014083   |\n",
      "|    std                  | 0.887        |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.95        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1329         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032904267 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.699        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | 2.2e-05      |\n",
      "|    reward               | -0.111007854 |\n",
      "|    std                  | 0.891        |\n",
      "|    value_loss           | 1.68         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.962       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067622927 |\n",
      "|    clip_fraction        | 0.0666       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.785        |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | 0.4602533    |\n",
      "|    std                  | 0.885        |\n",
      "|    value_loss           | 1.64         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.89        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1332         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039032516 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.552        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000725    |\n",
      "|    reward               | -0.09327892  |\n",
      "|    std                  | 0.88         |\n",
      "|    value_loss           | 1.31         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.911       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014288763 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.22         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    reward               | -1.4165914   |\n",
      "|    std                  | 0.884        |\n",
      "|    value_loss           | 1.85         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.854       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1334         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060026217 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.799        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | -0.3580597   |\n",
      "|    std                  | 0.871        |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -0.792      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1335        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003677573 |\n",
      "|    clip_fraction        | 0.00664     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.822       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 5.7e-05     |\n",
      "|    reward               | 0.6219689   |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -0.803       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1337         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022486679 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.366        |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    reward               | 0.49854657   |\n",
      "|    std                  | 0.858        |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -0.649      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1338        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004008774 |\n",
      "|    clip_fraction        | 0.0314      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00097    |\n",
      "|    reward               | -0.10840585 |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 1.96        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -0.402      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1339        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004820086 |\n",
      "|    clip_fraction        | 0.00991     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.000101   |\n",
      "|    reward               | 0.032438558 |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 1.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -0.242      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1340        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000890499 |\n",
      "|    clip_fraction        | 0.00474     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.432       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 4.51e-05    |\n",
      "|    reward               | 0.2567994   |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.0803       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1341         |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.002881552  |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.788        |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -4.56e-05    |\n",
      "|    reward               | -0.050405998 |\n",
      "|    std                  | 0.86         |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.229        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1342         |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030832246 |\n",
      "|    clip_fraction        | 0.0314       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.82         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    reward               | -0.013620821 |\n",
      "|    std                  | 0.855        |\n",
      "|    value_loss           | 1.88         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.392        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1343         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037733333 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.904        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.000801    |\n",
      "|    reward               | 0.11482262   |\n",
      "|    std                  | 0.856        |\n",
      "|    value_loss           | 1.81         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.451        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1344         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030652129 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.432        |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.000592    |\n",
      "|    reward               | 0.1542159    |\n",
      "|    std                  | 0.866        |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 0.409         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1345          |\n",
      "|    iterations           | 59            |\n",
      "|    time_elapsed         | 89            |\n",
      "|    total_timesteps      | 120832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020623326 |\n",
      "|    clip_fraction        | 0.00937       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.27         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.577         |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | -0.000441     |\n",
      "|    reward               | 0.28275025    |\n",
      "|    std                  | 0.853         |\n",
      "|    value_loss           | 1.59          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.592       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003084576 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.584       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.000873   |\n",
      "|    reward               | 0.011359399 |\n",
      "|    std                  | 0.849       |\n",
      "|    value_loss           | 1.99        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 0.787         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1346          |\n",
      "|    iterations           | 61            |\n",
      "|    time_elapsed         | 92            |\n",
      "|    total_timesteps      | 124928        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095324416 |\n",
      "|    clip_fraction        | 0.00688       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.25         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.752         |\n",
      "|    n_updates            | 600           |\n",
      "|    policy_gradient_loss | -0.00104      |\n",
      "|    reward               | 0.31409594    |\n",
      "|    std                  | 0.837         |\n",
      "|    value_loss           | 1.88          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.843       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005626985 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 0.27545136  |\n",
      "|    std                  | 0.843       |\n",
      "|    value_loss           | 1.91        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 0.96         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1347         |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008573617 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.842        |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.000187    |\n",
      "|    reward               | -0.26426613  |\n",
      "|    std                  | 0.844        |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.16         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1348         |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.929517e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.567        |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | 0.000276     |\n",
      "|    reward               | -0.36986962  |\n",
      "|    std                  | 0.847        |\n",
      "|    value_loss           | 1.78         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.4          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1347         |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008533646 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.61         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.000805    |\n",
      "|    reward               | -0.24906042  |\n",
      "|    std                  | 0.862        |\n",
      "|    value_loss           | 1.63         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.44         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1348         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052278964 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | -0.27826536  |\n",
      "|    std                  | 0.851        |\n",
      "|    value_loss           | 1.79         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.52         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1349         |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016891505 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.27         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.000338    |\n",
      "|    reward               | -0.5928544   |\n",
      "|    std                  | 0.861        |\n",
      "|    value_loss           | 1.97         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.42         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1350         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012835413 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.82         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    reward               | -0.58202326  |\n",
      "|    std                  | 0.865        |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.4          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1350         |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020679808 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.642        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.000267    |\n",
      "|    reward               | -0.46564057  |\n",
      "|    std                  | 0.856        |\n",
      "|    value_loss           | 1.91         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 1.45        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1350        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004418173 |\n",
      "|    clip_fraction        | 0.00425     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.04        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.000238   |\n",
      "|    reward               | 0.2796701   |\n",
      "|    std                  | 0.838       |\n",
      "|    value_loss           | 1.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 1.55        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1351        |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000553092 |\n",
      "|    clip_fraction        | 0.00522     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.719       |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.000179   |\n",
      "|    reward               | 1.0851445   |\n",
      "|    std                  | 0.829       |\n",
      "|    value_loss           | 1.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 1.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1351        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002117995 |\n",
      "|    clip_fraction        | 0.00972     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.52        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | 2.17e-05    |\n",
      "|    reward               | -0.4371461  |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 1.97         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1352         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044350782 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.642        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    reward               | -0.031751405 |\n",
      "|    std                  | 0.817        |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 2.28          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1352          |\n",
      "|    iterations           | 74            |\n",
      "|    time_elapsed         | 112           |\n",
      "|    total_timesteps      | 151552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058518554 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.22         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.19          |\n",
      "|    n_updates            | 730           |\n",
      "|    policy_gradient_loss | 0.000416      |\n",
      "|    reward               | -0.6613349    |\n",
      "|    std                  | 0.822         |\n",
      "|    value_loss           | 1.93          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 2.4           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1353          |\n",
      "|    iterations           | 75            |\n",
      "|    time_elapsed         | 113           |\n",
      "|    total_timesteps      | 153600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016152064 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.22         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.374         |\n",
      "|    n_updates            | 740           |\n",
      "|    policy_gradient_loss | 0.000416      |\n",
      "|    reward               | -1.6898309    |\n",
      "|    std                  | 0.821         |\n",
      "|    value_loss           | 1.71          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.47         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1353         |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034336653 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 1.5910245    |\n",
      "|    std                  | 0.83         |\n",
      "|    value_loss           | 1.8          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 2.52          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1353          |\n",
      "|    iterations           | 77            |\n",
      "|    time_elapsed         | 116           |\n",
      "|    total_timesteps      | 157696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023724473 |\n",
      "|    clip_fraction        | 0.00674       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.487         |\n",
      "|    n_updates            | 760           |\n",
      "|    policy_gradient_loss | 0.000207      |\n",
      "|    reward               | -2.4081385    |\n",
      "|    std                  | 0.832         |\n",
      "|    value_loss           | 1.57          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.44         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1353         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015300738 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.42         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.000409    |\n",
      "|    reward               | -0.0734524   |\n",
      "|    std                  | 0.827        |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.28         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1353         |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010094234 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.422        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | -0.3109578   |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 1.42         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 2.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1354        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002447416 |\n",
      "|    clip_fraction        | 0.00581     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.862       |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.000516   |\n",
      "|    reward               | 0.1268083   |\n",
      "|    std                  | 0.833       |\n",
      "|    value_loss           | 1.89        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 2.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1354        |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004340356 |\n",
      "|    clip_fraction        | 0.00981     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.357       |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.000806   |\n",
      "|    reward               | 0.17604868  |\n",
      "|    std                  | 0.827       |\n",
      "|    value_loss           | 1.88        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.37         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1354         |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004977667  |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    reward               | -0.044116117 |\n",
      "|    std                  | 0.818        |\n",
      "|    value_loss           | 1.98         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 2.31          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1352          |\n",
      "|    iterations           | 83            |\n",
      "|    time_elapsed         | 125           |\n",
      "|    total_timesteps      | 169984        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021427064 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.21         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.761         |\n",
      "|    n_updates            | 820           |\n",
      "|    policy_gradient_loss | 0.000331      |\n",
      "|    reward               | 0.21559559    |\n",
      "|    std                  | 0.812         |\n",
      "|    value_loss           | 1.65          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.27         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1351         |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046578897 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.984        |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.000957    |\n",
      "|    reward               | -0.25861296  |\n",
      "|    std                  | 0.813        |\n",
      "|    value_loss           | 1.86         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 2.29          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 85            |\n",
      "|    time_elapsed         | 128           |\n",
      "|    total_timesteps      | 174080        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068980677 |\n",
      "|    clip_fraction        | 0.000439      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.21         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.22          |\n",
      "|    n_updates            | 840           |\n",
      "|    policy_gradient_loss | 0.000214      |\n",
      "|    reward               | 0.18300733    |\n",
      "|    std                  | 0.805         |\n",
      "|    value_loss           | 1.87          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 2.43        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005225818 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    reward               | -0.20548864 |\n",
      "|    std                  | 0.805       |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 2.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003940182 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.922       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.000785   |\n",
      "|    reward               | -0.19904909 |\n",
      "|    std                  | 0.807       |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.41         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1345         |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033128792 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.907        |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.000243    |\n",
      "|    reward               | -0.19295207  |\n",
      "|    std                  | 0.802        |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.52         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1343         |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053172237 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.9          |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    reward               | 0.052211262  |\n",
      "|    std                  | 0.799        |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.65         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1341         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006788239 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.656        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | 8.72e-05     |\n",
      "|    reward               | 0.2099498    |\n",
      "|    std                  | 0.809        |\n",
      "|    value_loss           | 1.75         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.71         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1340         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016824268 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1            |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | 0.000205     |\n",
      "|    reward               | 0.32994094   |\n",
      "|    std                  | 0.812        |\n",
      "|    value_loss           | 1.87         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.77         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1339         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012944276 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | 0.000307     |\n",
      "|    reward               | 0.3940146    |\n",
      "|    std                  | 0.817        |\n",
      "|    value_loss           | 1.85         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 2.93         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1339         |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 142          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021477842 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.495        |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | 0.000166     |\n",
      "|    reward               | 0.011118128  |\n",
      "|    std                  | 0.817        |\n",
      "|    value_loss           | 2            |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 2.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1337        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002480043 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.43        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.000759   |\n",
      "|    reward               | 0.45634145  |\n",
      "|    std                  | 0.812       |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 2.99          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1337          |\n",
      "|    iterations           | 95            |\n",
      "|    time_elapsed         | 145           |\n",
      "|    total_timesteps      | 194560        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013525854 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.21         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.01          |\n",
      "|    n_updates            | 940           |\n",
      "|    policy_gradient_loss | 0.000451      |\n",
      "|    reward               | 0.9915258     |\n",
      "|    std                  | 0.816         |\n",
      "|    value_loss           | 1.89          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.01         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1335         |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024638749 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.000181    |\n",
      "|    reward               | -0.5169115   |\n",
      "|    std                  | 0.811        |\n",
      "|    value_loss           | 1.74         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.17         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1334         |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023575092 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.966        |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -6.24e-05    |\n",
      "|    reward               | -0.35879403  |\n",
      "|    std                  | 0.824        |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 3.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1333        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003628018 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.55        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.000347   |\n",
      "|    reward               | -0.5832261  |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 1.94        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.43         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 202752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028104929 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.846        |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.000958    |\n",
      "|    reward               | -0.32842425  |\n",
      "|    std                  | 0.813        |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.52         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1330         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028647557 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.000686    |\n",
      "|    reward               | 0.46692005   |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 1.81         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1329         |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005834486 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.000189    |\n",
      "|    reward               | -0.4548831   |\n",
      "|    std                  | 0.842        |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.73         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1330         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036441186 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.59         |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    reward               | 0.09541663   |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.73         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1330         |\n",
      "|    iterations           | 103          |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 210944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056771794 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.826        |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    reward               | -0.54155564  |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.83         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042494647 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.04         |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.000736    |\n",
      "|    reward               | 0.078905836  |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.88         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029806267 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.07         |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.000265    |\n",
      "|    reward               | 1.4468646    |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 3.93         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1332         |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038336269 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.58         |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | 0.2789209    |\n",
      "|    std                  | 0.842        |\n",
      "|    value_loss           | 1.98         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 3.99        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1333        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004532023 |\n",
      "|    clip_fraction        | 0.00693     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.01        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.000481   |\n",
      "|    reward               | -0.37072068 |\n",
      "|    std                  | 0.846       |\n",
      "|    value_loss           | 2.05        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.05         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021339892 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.479        |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.00029     |\n",
      "|    reward               | -0.22181854  |\n",
      "|    std                  | 0.845        |\n",
      "|    value_loss           | 1.57         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.34         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024003563 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.499        |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | 0.000107     |\n",
      "|    reward               | -0.08497448  |\n",
      "|    std                  | 0.853        |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.38         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1334         |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045420583 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.434        |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    reward               | 0.16093557   |\n",
      "|    std                  | 0.842        |\n",
      "|    value_loss           | 1.96         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 4.38          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1335          |\n",
      "|    iterations           | 111           |\n",
      "|    time_elapsed         | 170           |\n",
      "|    total_timesteps      | 227328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0023572585  |\n",
      "|    clip_fraction        | 0.013         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.24         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.921         |\n",
      "|    n_updates            | 1100          |\n",
      "|    policy_gradient_loss | -0.000708     |\n",
      "|    reward               | -0.0049676625 |\n",
      "|    std                  | 0.835         |\n",
      "|    value_loss           | 1.96          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.44         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1335         |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019414348 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.13         |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.000149    |\n",
      "|    reward               | -0.13899557  |\n",
      "|    std                  | 0.832        |\n",
      "|    value_loss           | 1.9          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 4.56          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1336          |\n",
      "|    iterations           | 113           |\n",
      "|    time_elapsed         | 173           |\n",
      "|    total_timesteps      | 231424        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050856615 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.63          |\n",
      "|    n_updates            | 1120          |\n",
      "|    policy_gradient_loss | 0.000294      |\n",
      "|    reward               | 0.09421268    |\n",
      "|    std                  | 0.83          |\n",
      "|    value_loss           | 2.01          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.59         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1336         |\n",
      "|    iterations           | 114          |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004783796  |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.631        |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | -0.00097     |\n",
      "|    reward               | -0.012949348 |\n",
      "|    std                  | 0.823        |\n",
      "|    value_loss           | 1.98         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.54         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1336         |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036032014 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.796        |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.000252    |\n",
      "|    reward               | 0.34633553   |\n",
      "|    std                  | 0.819        |\n",
      "|    value_loss           | 2.01         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 4.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1337        |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003367545 |\n",
      "|    clip_fraction        | 0.0349      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.659       |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    reward               | -0.10767791 |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 4.63          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1337          |\n",
      "|    iterations           | 117           |\n",
      "|    time_elapsed         | 179           |\n",
      "|    total_timesteps      | 239616        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9782527e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.21         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.481         |\n",
      "|    n_updates            | 1160          |\n",
      "|    policy_gradient_loss | 0.000279      |\n",
      "|    reward               | 0.16881807    |\n",
      "|    std                  | 0.817         |\n",
      "|    value_loss           | 1.98          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.66         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1338         |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040021315 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.28         |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.000671    |\n",
      "|    reward               | -0.4641013   |\n",
      "|    std                  | 0.813        |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 4.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1338        |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003710155 |\n",
      "|    clip_fraction        | 0.00771     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.847       |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.000832   |\n",
      "|    reward               | 0.18895625  |\n",
      "|    std                  | 0.807       |\n",
      "|    value_loss           | 1.99        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.87         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1339         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036879927 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    reward               | -0.2188696   |\n",
      "|    std                  | 0.806        |\n",
      "|    value_loss           | 1.97         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 4.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1339        |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003887372 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.844       |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.000895   |\n",
      "|    reward               | -0.30763596 |\n",
      "|    std                  | 0.799       |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.99         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1340         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 186          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030589206 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.55         |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.000358    |\n",
      "|    reward               | 0.20479675   |\n",
      "|    std                  | 0.797        |\n",
      "|    value_loss           | 1.98         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.97         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1340         |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 187          |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065146894 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.75         |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    reward               | -0.2322409   |\n",
      "|    std                  | 0.796        |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.96         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1340         |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 189          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005876495 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.00027     |\n",
      "|    reward               | -0.041320693 |\n",
      "|    std                  | 0.811        |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 4.97         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1341         |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034877798 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.677        |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.000133    |\n",
      "|    reward               | -0.3299369   |\n",
      "|    std                  | 0.816        |\n",
      "|    value_loss           | 1.96         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.1          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1341         |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030941376 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.897        |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | 0.000643     |\n",
      "|    reward               | 0.16166939   |\n",
      "|    std                  | 0.818        |\n",
      "|    value_loss           | 1.96         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.26         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1340         |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 260096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030311327 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.931        |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | -0.19935283  |\n",
      "|    std                  | 0.817        |\n",
      "|    value_loss           | 2            |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 5.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1339        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003180644 |\n",
      "|    clip_fraction        | 0.00518     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.82        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -5.23e-05   |\n",
      "|    reward               | -0.1819275  |\n",
      "|    std                  | 0.805       |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.29         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1338         |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 264192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036797817 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | 0.18101701   |\n",
      "|    std                  | 0.795        |\n",
      "|    value_loss           | 1.88         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.45         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1337         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056035607 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.562        |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | 0.23563974   |\n",
      "|    std                  | 0.795        |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.48         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1336         |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 268288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037756264 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.387        |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.000546    |\n",
      "|    reward               | 0.5050775    |\n",
      "|    std                  | 0.796        |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 5.5           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1336          |\n",
      "|    iterations           | 132           |\n",
      "|    time_elapsed         | 202           |\n",
      "|    total_timesteps      | 270336        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030288915 |\n",
      "|    clip_fraction        | 0.00459       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.19         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.578         |\n",
      "|    n_updates            | 1310          |\n",
      "|    policy_gradient_loss | 0.000101      |\n",
      "|    reward               | -0.83297765   |\n",
      "|    std                  | 0.791         |\n",
      "|    value_loss           | 1.99          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.56         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1335         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023906864 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.000738    |\n",
      "|    reward               | 0.058315296  |\n",
      "|    std                  | 0.792        |\n",
      "|    value_loss           | 1.96         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.67         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1334         |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047781025 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.728        |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.000598    |\n",
      "|    reward               | 0.5780812    |\n",
      "|    std                  | 0.794        |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 5.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1334        |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006620948 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    reward               | 2.581595    |\n",
      "|    std                  | 0.789       |\n",
      "|    value_loss           | 1.96        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.78         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1333         |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019901725 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.563        |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    reward               | -0.26149127  |\n",
      "|    std                  | 0.767        |\n",
      "|    value_loss           | 1.97         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 5.83        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1332        |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004968988 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.771       |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.000678   |\n",
      "|    reward               | 0.05004367  |\n",
      "|    std                  | 0.765       |\n",
      "|    value_loss           | 1.57        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.85         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026959167 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.02         |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.000645    |\n",
      "|    reward               | 0.3742674    |\n",
      "|    std                  | 0.762        |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 5.88         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1330         |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 213          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044384645 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.763        |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    reward               | -0.27591506  |\n",
      "|    std                  | 0.762        |\n",
      "|    value_loss           | 1.98         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 5.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1330        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005900205 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 0.018017381 |\n",
      "|    std                  | 0.756       |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | 5.96          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1330          |\n",
      "|    iterations           | 141           |\n",
      "|    time_elapsed         | 217           |\n",
      "|    total_timesteps      | 288768        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0018237385  |\n",
      "|    clip_fraction        | 0.00991       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.13         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.39          |\n",
      "|    n_updates            | 1400          |\n",
      "|    policy_gradient_loss | -0.000676     |\n",
      "|    reward               | -0.0035966213 |\n",
      "|    std                  | 0.735         |\n",
      "|    value_loss           | 1.99          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 6.04         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1330         |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010479972 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.927        |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | 0.00016      |\n",
      "|    reward               | 0.08601322   |\n",
      "|    std                  | 0.735        |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 6.01         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003494516 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.828        |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | 0.000211     |\n",
      "|    reward               | -0.2739278   |\n",
      "|    std                  | 0.743        |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 6.02         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029376608 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.631        |\n",
      "|    n_updates            | 1430         |\n",
      "|    policy_gradient_loss | 6e-05        |\n",
      "|    reward               | 0.12596056   |\n",
      "|    std                  | 0.739        |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 6.03         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1331         |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015679705 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | 0.000115     |\n",
      "|    reward               | 1.1570874    |\n",
      "|    std                  | 0.741        |\n",
      "|    value_loss           | 1.95         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 6.09         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1332         |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010388282 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.608        |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | 0.00034      |\n",
      "|    reward               | -0.30541012  |\n",
      "|    std                  | 0.738        |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | 6.17         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1332         |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 225          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021432587 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.823        |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | 0.000103     |\n",
      "|    reward               | -0.17446172  |\n",
      "|    std                  | 0.75         |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "✅ 模型儲存於：E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_4.zip\n",
      "🧠 訓練群 5：['0050.TW', '1301.TW', '1303.TW', '1326.TW']\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 355       |\n",
      "|    ep_rew_mean     | -30.7     |\n",
      "| time/              |           |\n",
      "|    fps             | 3000      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.7979868 |\n",
      "----------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 455         |\n",
      "|    ep_rew_mean          | -28         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1860        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007752659 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | -0.0468     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.9         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    reward               | -1.2132684  |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 434         |\n",
      "|    ep_rew_mean          | -28.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1669        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005167486 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | -0.00574    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    reward               | -0.26875362 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.89        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 443         |\n",
      "|    ep_rew_mean          | -27.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1579        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008669366 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | -0.00268    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.38        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    reward               | 1.02888     |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 386         |\n",
      "|    ep_rew_mean          | -28         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1529        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006792908 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.00143     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.84        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    reward               | -0.19811422 |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 393          |\n",
      "|    ep_rew_mean          | -28.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1500         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053509707 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.65        |\n",
      "|    explained_variance   | -0.000588    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.32         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    reward               | -0.5359851   |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 421          |\n",
      "|    ep_rew_mean          | -27.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1463         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061922027 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.65        |\n",
      "|    explained_variance   | 0.00908      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.67         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    reward               | 0.71763754   |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 9.21         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 429          |\n",
      "|    ep_rew_mean          | -26.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1450         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075108064 |\n",
      "|    clip_fraction        | 0.0703       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.66        |\n",
      "|    explained_variance   | -0.016       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.74         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0095      |\n",
      "|    reward               | 2.546865     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 11.6         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 418          |\n",
      "|    ep_rew_mean          | -26.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1429         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076712514 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | -0.00769     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.01         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00802     |\n",
      "|    reward               | 4.046095     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 10.3         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 438          |\n",
      "|    ep_rew_mean          | -25.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1420         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059139393 |\n",
      "|    clip_fraction        | 0.052        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | -0.000887    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.21         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    reward               | -1.3759598   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 13.7         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 390           |\n",
      "|    ep_rew_mean          | -26.1         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1402          |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.007548646   |\n",
      "|    clip_fraction        | 0.0726        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.72         |\n",
      "|    explained_variance   | 0.000483      |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 5.12          |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.00687      |\n",
      "|    reward               | -0.0037803673 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 10.3          |\n",
      "-------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 396          |\n",
      "|    ep_rew_mean          | -26.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1395         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065129194 |\n",
      "|    clip_fraction        | 0.0638       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.00805      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.5          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00852     |\n",
      "|    reward               | 0.5057797    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 18.8         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 411          |\n",
      "|    ep_rew_mean          | -25.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1388         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069997762 |\n",
      "|    clip_fraction        | 0.076        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | -0.00998     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.36         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    reward               | -0.09307953  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 403         |\n",
      "|    ep_rew_mean          | -26         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010844798 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | -0.0109     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.92        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | 1.2028767   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 9.42        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 413         |\n",
      "|    ep_rew_mean          | -25.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009700629 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.00484     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.65        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -0.5073833  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.8        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 421        |\n",
      "|    ep_rew_mean          | -25.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1375       |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00712974 |\n",
      "|    clip_fraction        | 0.0561     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.72      |\n",
      "|    explained_variance   | -0.0263    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.46       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.00597   |\n",
      "|    reward               | 1.11556    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 7.33       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 429         |\n",
      "|    ep_rew_mean          | -25.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1367        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008113325 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.00127     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.41        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    reward               | -1.4738346  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 432          |\n",
      "|    ep_rew_mean          | -25.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1368         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062063644 |\n",
      "|    clip_fraction        | 0.0705       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | -0.000481    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.69         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00789     |\n",
      "|    reward               | 0.26713464   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 11.4         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 436          |\n",
      "|    ep_rew_mean          | -25.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1364         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074095693 |\n",
      "|    clip_fraction        | 0.0727       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | -0.0142      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.96         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | -0.29793426  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 11.4         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 443          |\n",
      "|    ep_rew_mean          | -24.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068949508 |\n",
      "|    clip_fraction        | 0.0759       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.000333     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.09         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0075      |\n",
      "|    reward               | -0.051749934 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 12.3         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 452          |\n",
      "|    ep_rew_mean          | -24.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009657245  |\n",
      "|    clip_fraction        | 0.0701       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.000157     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.06         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    reward               | -0.014011695 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 460        |\n",
      "|    ep_rew_mean          | -24        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1361       |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01115215 |\n",
      "|    clip_fraction        | 0.0889     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.72      |\n",
      "|    explained_variance   | 0.00121    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.63       |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.00907   |\n",
      "|    reward               | 0.07570971 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 8.22       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 470         |\n",
      "|    ep_rew_mean          | -24         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007845791 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | -0.0161     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.85        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    reward               | -1.0650673  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 476         |\n",
      "|    ep_rew_mean          | -23.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008514985 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.00565     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.33        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    reward               | 1.058774    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.64        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 486         |\n",
      "|    ep_rew_mean          | -23         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1361        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006709735 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.00151     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.33        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    reward               | -0.5883117  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 497         |\n",
      "|    ep_rew_mean          | -22.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1359        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009804006 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | -0.00358    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.79        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    reward               | 0.9052668   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.38        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -22         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1359        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006758527 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    reward               | 1.2301463   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 511          |\n",
      "|    ep_rew_mean          | -21.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1358         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007680416  |\n",
      "|    clip_fraction        | 0.0657       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 0.00971      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.4          |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    reward               | -0.024845643 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 522         |\n",
      "|    ep_rew_mean          | -21.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1357        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011715606 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | -0.00626    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.19        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | -2.1146793  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 531         |\n",
      "|    ep_rew_mean          | -20.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009888768 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.0222      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    reward               | 0.4792145   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 540         |\n",
      "|    ep_rew_mean          | -19.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1355        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008272233 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0231      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.26        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    reward               | 1.9679      |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.39        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 549          |\n",
      "|    ep_rew_mean          | -19.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1355         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089002475 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.00226      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.79         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    reward               | 0.9744339    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 14.4         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 549         |\n",
      "|    ep_rew_mean          | -18.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386923 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.00426     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.68        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | 0.108480364 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 559         |\n",
      "|    ep_rew_mean          | -18.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009885114 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0172      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.4         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    reward               | 2.2548223   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 553         |\n",
      "|    ep_rew_mean          | -18.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006827769 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.24        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | -0.6150115  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 11.8        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 559         |\n",
      "|    ep_rew_mean          | -17.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009093561 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.44        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | 1.1415819   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 17.2        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 538        |\n",
      "|    ep_rew_mean          | -18        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1356       |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00862713 |\n",
      "|    clip_fraction        | 0.0901     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.75      |\n",
      "|    explained_variance   | 0.0325     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.29       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.00674   |\n",
      "|    reward               | 0.8122387  |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 13.3       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 554          |\n",
      "|    ep_rew_mean          | -17.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1357         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049403044 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | -0.0354      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.6          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    reward               | -2.3143435   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 560        |\n",
      "|    ep_rew_mean          | -17        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1357       |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01157248 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.74      |\n",
      "|    explained_variance   | -0.0389    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.61       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00891   |\n",
      "|    reward               | 2.0562449  |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 12.7       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 556        |\n",
      "|    ep_rew_mean          | -16.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1357       |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00565185 |\n",
      "|    clip_fraction        | 0.0598     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.74      |\n",
      "|    explained_variance   | 0.0324     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.99       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0044    |\n",
      "|    reward               | -2.8589525 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 16.7       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 561         |\n",
      "|    ep_rew_mean          | -16.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1357        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009813107 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00169     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.83        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    reward               | 2.5940464   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 574         |\n",
      "|    ep_rew_mean          | -15.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1358        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008043534 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0414      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.95        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | 0.54894656  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 574         |\n",
      "|    ep_rew_mean          | -15.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00857546  |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.22        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | -0.25684816 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 585         |\n",
      "|    ep_rew_mean          | -15         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1353        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012078848 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0695      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.71        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | -0.8304153  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 582         |\n",
      "|    ep_rew_mean          | -14.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007135177 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0336      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.72        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    reward               | -1.1776496  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 589        |\n",
      "|    ep_rew_mean          | -14.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1346       |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01181962 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.77      |\n",
      "|    explained_variance   | 0.0361     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.54       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.00435   |\n",
      "|    reward               | -1.3610836 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 17.1       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 584         |\n",
      "|    ep_rew_mean          | -14.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1342        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013037832 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0685      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.48        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    reward               | 0.35698217  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 587         |\n",
      "|    ep_rew_mean          | -13.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1340        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008453395 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0497      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.12        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    reward               | 1.5248935   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 597         |\n",
      "|    ep_rew_mean          | -13.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1337        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005929951 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0438      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.7         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    reward               | 1.3561729   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 594         |\n",
      "|    ep_rew_mean          | -13.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1333        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011403516 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | -0.00941    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.23        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 0.000215    |\n",
      "|    reward               | -1.3952285  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 594         |\n",
      "|    ep_rew_mean          | -12.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1330        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010862552 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0745      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    reward               | 2.0490358   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 591         |\n",
      "|    ep_rew_mean          | -12.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1328        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008108158 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | 0.0357      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.12        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    reward               | 0.7058228   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 582        |\n",
      "|    ep_rew_mean          | -12.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1325       |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 81         |\n",
      "|    total_timesteps      | 108544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00906626 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.78      |\n",
      "|    explained_variance   | 0.141      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.95       |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0045    |\n",
      "|    reward               | -1.7552737 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 586         |\n",
      "|    ep_rew_mean          | -11.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005594761 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.15        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    reward               | -0.8103869  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 583         |\n",
      "|    ep_rew_mean          | -11.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008185169 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.24        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | 0.091233246 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 582         |\n",
      "|    ep_rew_mean          | -11.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009043282 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.0904      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.97        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | 0.000162    |\n",
      "|    reward               | -1.8877825  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 576         |\n",
      "|    ep_rew_mean          | -11.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009158626 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0334      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.64        |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | -1.324036   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 569          |\n",
      "|    ep_rew_mean          | -11.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100611085 |\n",
      "|    clip_fraction        | 0.096        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | 0.058        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.97         |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    reward               | -0.7896133   |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 16.4         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 576        |\n",
      "|    ep_rew_mean          | -11.2      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 92         |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00831698 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.82      |\n",
      "|    explained_variance   | 0.0229     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.48       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.00322   |\n",
      "|    reward               | 0.9692434  |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 17.2       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 577          |\n",
      "|    ep_rew_mean          | -10.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058482112 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | 0.061        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.8          |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | 1.2843367    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 564         |\n",
      "|    ep_rew_mean          | -11.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009860563 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0328      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.69        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | 0.8938698   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 563         |\n",
      "|    ep_rew_mean          | -11         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010248354 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.35        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    reward               | -1.1291425  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 562         |\n",
      "|    ep_rew_mean          | -11.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012713384 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.000632   |\n",
      "|    reward               | -2.2930071  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 562         |\n",
      "|    ep_rew_mean          | -11         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009412428 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.64        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | -2.8664398  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 582         |\n",
      "|    ep_rew_mean          | -10.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009790529 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.37        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | -4.435987   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 595         |\n",
      "|    ep_rew_mean          | -9.55       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022167243 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.0678      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    reward               | -0.14728132 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 608         |\n",
      "|    ep_rew_mean          | -8.97       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017614301 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | 0.0701      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    reward               | 0.8160409   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 615         |\n",
      "|    ep_rew_mean          | -8.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013941832 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.76        |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    reward               | -1.0289047  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 620         |\n",
      "|    ep_rew_mean          | -7.75       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019117076 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.43        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.00139     |\n",
      "|    reward               | -1.1333348  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 632         |\n",
      "|    ep_rew_mean          | -7.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011326983 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.53        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | -0.7350131  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 635         |\n",
      "|    ep_rew_mean          | -6.96       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012800781 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.28        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.000769   |\n",
      "|    reward               | -0.1539713  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 639         |\n",
      "|    ep_rew_mean          | -6.46       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009651771 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.000209   |\n",
      "|    reward               | 0.24899785  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 639         |\n",
      "|    ep_rew_mean          | -5.98       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011673192 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | 0.0444      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.68        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    reward               | 2.054127    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 635         |\n",
      "|    ep_rew_mean          | -5.79       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013193178 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.89       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.55        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    reward               | 0.17769326  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 632         |\n",
      "|    ep_rew_mean          | -5.88       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009524802 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.91       |\n",
      "|    explained_variance   | 0.0916      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.64        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.000433   |\n",
      "|    reward               | -1.0783248  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 634         |\n",
      "|    ep_rew_mean          | -5.91       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007089913 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    reward               | 1.6925751   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 641          |\n",
      "|    ep_rew_mean          | -5.61        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067118406 |\n",
      "|    clip_fraction        | 0.0636       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.92        |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.34         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -0.24453704  |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 632          |\n",
      "|    ep_rew_mean          | -5.55        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072454633 |\n",
      "|    clip_fraction        | 0.0723       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.92        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | -0.08986956  |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 15.2         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 636         |\n",
      "|    ep_rew_mean          | -5.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005787353 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.0646      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | -0.4467717  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 633        |\n",
      "|    ep_rew_mean          | -5.59      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1315       |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01545517 |\n",
      "|    clip_fraction        | 0.0902     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.92      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 6.25       |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.00254   |\n",
      "|    reward               | 1.239206   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 15.4       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 638         |\n",
      "|    ep_rew_mean          | -4.97       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012299163 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.91       |\n",
      "|    explained_variance   | 0.0747      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.14        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.000778   |\n",
      "|    reward               | 0.678177    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 634        |\n",
      "|    ep_rew_mean          | -4.97      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 127        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01071761 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.92      |\n",
      "|    explained_variance   | 0.107      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 11.3       |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | 0.00181    |\n",
      "|    reward               | 0.966554   |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 15.6       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 635         |\n",
      "|    ep_rew_mean          | -4.94       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009070481 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.91       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.46        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | 9.05e-05    |\n",
      "|    reward               | 4.1391096   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 635         |\n",
      "|    ep_rew_mean          | -5.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011763719 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.9        |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.42        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    reward               | 0.28614184  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 638          |\n",
      "|    ep_rew_mean          | -4.78        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102495365 |\n",
      "|    clip_fraction        | 0.0911       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.9         |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.48         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | -1.8565718   |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 16.8         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 638         |\n",
      "|    ep_rew_mean          | -4.63       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011323817 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.9        |\n",
      "|    explained_variance   | 0.0843      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.32        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.000842   |\n",
      "|    reward               | -2.2197363  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 19.5        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 642         |\n",
      "|    ep_rew_mean          | -4.62       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008449366 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.91       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    reward               | -0.85068816 |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 631         |\n",
      "|    ep_rew_mean          | -5.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012041328 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.48        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    reward               | -2.6110415  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16          |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 641        |\n",
      "|    ep_rew_mean          | -4.51      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1319       |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0080241  |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.91      |\n",
      "|    explained_variance   | 0.178      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.15       |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | -2.78e-05  |\n",
      "|    reward               | -1.0563396 |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 19         |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 648         |\n",
      "|    ep_rew_mean          | -4.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1319        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014076631 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.91       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    reward               | -0.87105364 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 645         |\n",
      "|    ep_rew_mean          | -4.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009445954 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.092       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.97        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    reward               | 2.4109757   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 646         |\n",
      "|    ep_rew_mean          | -4.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017557738 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.83        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.000369   |\n",
      "|    reward               | 1.160427    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 662         |\n",
      "|    ep_rew_mean          | -2.95       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010698373 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.0591      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.64        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | 0.00026     |\n",
      "|    reward               | 0.8932802   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -2.58       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009087641 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.0862      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.26        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00027    |\n",
      "|    reward               | -0.7070166  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -2.53       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010013424 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.93       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.95        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    reward               | -0.12933469 |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 676         |\n",
      "|    ep_rew_mean          | -2.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011318804 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.94       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | 0.24757805  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 20.6        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 683         |\n",
      "|    ep_rew_mean          | -1.68       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011419373 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.95       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.97        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    reward               | 0.87067544  |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 687         |\n",
      "|    ep_rew_mean          | -1.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010296494 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.96       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.65        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | 0.3606365   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 15.7        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 693        |\n",
      "|    ep_rew_mean          | -0.768     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 154        |\n",
      "|    total_timesteps      | 202752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00962224 |\n",
      "|    clip_fraction        | 0.0705     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.97      |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.7        |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.00378   |\n",
      "|    reward               | -1.2897594 |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 16.6       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 690          |\n",
      "|    ep_rew_mean          | -1.11        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080084335 |\n",
      "|    clip_fraction        | 0.0785       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.97        |\n",
      "|    explained_variance   | 0.0915       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.94         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    reward               | 0.22840917   |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 17.5         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 681         |\n",
      "|    ep_rew_mean          | -1.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006944556 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | 0.12658308  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 684         |\n",
      "|    ep_rew_mean          | -1.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008115173 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.68        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | -0.90788865 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 685         |\n",
      "|    ep_rew_mean          | -1.65       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006740182 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    reward               | 0.2738316   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 685         |\n",
      "|    ep_rew_mean          | -1.44       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011704395 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.92        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    reward               | -0.9519698  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 689         |\n",
      "|    ep_rew_mean          | -1.33       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013542089 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    reward               | 2.0138197   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 690        |\n",
      "|    ep_rew_mean          | -1.32      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1319       |\n",
      "|    iterations           | 106        |\n",
      "|    time_elapsed         | 164        |\n",
      "|    total_timesteps      | 217088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01920446 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.97      |\n",
      "|    explained_variance   | 0.0972     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.41       |\n",
      "|    n_updates            | 1050       |\n",
      "|    policy_gradient_loss | 0.00127    |\n",
      "|    reward               | 0.9699306  |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 19.2       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 690          |\n",
      "|    ep_rew_mean          | -1.33        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1319         |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109768035 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.98        |\n",
      "|    explained_variance   | 0.0788       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.19         |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | 0.000653     |\n",
      "|    reward               | 1.1986711    |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 691         |\n",
      "|    ep_rew_mean          | -1.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1319        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010234073 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.6         |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.000107   |\n",
      "|    reward               | 0.42532763  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 691         |\n",
      "|    ep_rew_mean          | -0.805      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009727657 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    reward               | 2.1745915   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 21          |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 691         |\n",
      "|    ep_rew_mean          | -0.451      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004945233 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.66        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | -2.3249192  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 694          |\n",
      "|    ep_rew_mean          | 0.0865       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1320         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060466416 |\n",
      "|    clip_fraction        | 0.0879       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.98        |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.96         |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    reward               | 2.073279     |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 20.7         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 699         |\n",
      "|    ep_rew_mean          | 0.309       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1321        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009949928 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    reward               | 0.14047325  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 705         |\n",
      "|    ep_rew_mean          | 0.826       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1321        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007720235 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6          |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    reward               | -1.0445064  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 702         |\n",
      "|    ep_rew_mean          | 0.763       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1321        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008885741 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.95        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | -0.4493498  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 699         |\n",
      "|    ep_rew_mean          | 0.423       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1322        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009792952 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.99        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    reward               | -0.70818055 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 706          |\n",
      "|    ep_rew_mean          | 0.93         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1322         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072865104 |\n",
      "|    clip_fraction        | 0.0852       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.01        |\n",
      "|    explained_variance   | 0.148        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.35         |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    reward               | -0.7647251   |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 19.6         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 703         |\n",
      "|    ep_rew_mean          | 0.811       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1323        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007858784 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.42        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    reward               | 0.8753088   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 18.1        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 703        |\n",
      "|    ep_rew_mean          | 1.03       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1323       |\n",
      "|    iterations           | 118        |\n",
      "|    time_elapsed         | 182        |\n",
      "|    total_timesteps      | 241664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02085039 |\n",
      "|    clip_fraction        | 0.0986     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.01      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.2       |\n",
      "|    n_updates            | 1170       |\n",
      "|    policy_gradient_loss | -0.000649  |\n",
      "|    reward               | -1.550616  |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 21.5       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 703         |\n",
      "|    ep_rew_mean          | 1.19        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1323        |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005798124 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.000554   |\n",
      "|    reward               | 0.81791896  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 704         |\n",
      "|    ep_rew_mean          | 1.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1323        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 185         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014419293 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.02       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.06        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | 0.000965    |\n",
      "|    reward               | 0.58451796  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 19.3        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 704         |\n",
      "|    ep_rew_mean          | 1.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1323        |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014185946 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.02       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.92        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -1.09e-05   |\n",
      "|    reward               | -0.4677001  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 710         |\n",
      "|    ep_rew_mean          | 1.73        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1322        |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012503194 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.92        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.000957   |\n",
      "|    reward               | -0.20358141 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 19.2        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 711         |\n",
      "|    ep_rew_mean          | 1.85        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1321        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018458843 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.45        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | 0.000188    |\n",
      "|    reward               | -0.9378179  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 701         |\n",
      "|    ep_rew_mean          | 1.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008522036 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.18        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    reward               | 0.9095739   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18.9        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 708         |\n",
      "|    ep_rew_mean          | 1.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009628329 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.16        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    reward               | 1.2275081   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 708         |\n",
      "|    ep_rew_mean          | 1.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1319        |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011462349 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    reward               | -0.69242865 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18.7        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 705         |\n",
      "|    ep_rew_mean          | 1.47        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009647499 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.183       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.000294   |\n",
      "|    reward               | 1.4717848   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 705         |\n",
      "|    ep_rew_mean          | 1.55        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010012524 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.71        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.000802   |\n",
      "|    reward               | -0.78633547 |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 18.2        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 705          |\n",
      "|    ep_rew_mean          | 1.68         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 200          |\n",
      "|    total_timesteps      | 264192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055550504 |\n",
      "|    clip_fraction        | 0.0838       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.98        |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11           |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    reward               | 0.5955344    |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 18.8         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 706          |\n",
      "|    ep_rew_mean          | 1.59         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 202          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066541694 |\n",
      "|    clip_fraction        | 0.0701       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.97        |\n",
      "|    explained_variance   | 0.208        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.45         |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | -1.5773345   |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 19.7         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 700        |\n",
      "|    ep_rew_mean          | 1.47       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1315       |\n",
      "|    iterations           | 131        |\n",
      "|    time_elapsed         | 204        |\n",
      "|    total_timesteps      | 268288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00864839 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.98      |\n",
      "|    explained_variance   | 0.264      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.2        |\n",
      "|    n_updates            | 1300       |\n",
      "|    policy_gradient_loss | -0.00121   |\n",
      "|    reward               | 1.3556961  |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 18.3       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 697         |\n",
      "|    ep_rew_mean          | 1.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016265532 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.37        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | 0.00114     |\n",
      "|    reward               | -0.5500776  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 690          |\n",
      "|    ep_rew_mean          | 0.735        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077318093 |\n",
      "|    clip_fraction        | 0.089        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.97        |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.49         |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    reward               | 0.2096527    |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 691          |\n",
      "|    ep_rew_mean          | 0.825        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118376855 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.98        |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | 0.00311      |\n",
      "|    reward               | -1.1886806   |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 19           |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 684         |\n",
      "|    ep_rew_mean          | 0.575       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013890324 |\n",
      "|    clip_fraction        | 0.0714      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.86        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | 0.00114     |\n",
      "|    reward               | -0.26273873 |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 20.8        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 688         |\n",
      "|    ep_rew_mean          | 1.04        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008520641 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.61        |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | 0.000687    |\n",
      "|    reward               | 0.93592787  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 688        |\n",
      "|    ep_rew_mean          | 0.933      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1313       |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00636705 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6         |\n",
      "|    explained_variance   | 0.202      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.3        |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | -0.00208   |\n",
      "|    reward               | -1.1008962 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 16.5       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 688         |\n",
      "|    ep_rew_mean          | 0.847       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007371133 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.51        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    reward               | 1.4448674   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 687         |\n",
      "|    ep_rew_mean          | 0.866       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012031495 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.000768   |\n",
      "|    reward               | -1.7864413  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 687          |\n",
      "|    ep_rew_mean          | 0.962        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077539794 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6           |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.07         |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.000146    |\n",
      "|    reward               | -0.90383047  |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 687          |\n",
      "|    ep_rew_mean          | 0.858        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 219          |\n",
      "|    total_timesteps      | 288768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069015697 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6           |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 2.0295033    |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 694        |\n",
      "|    ep_rew_mean          | 1.28       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1314       |\n",
      "|    iterations           | 142        |\n",
      "|    time_elapsed         | 221        |\n",
      "|    total_timesteps      | 290816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00668609 |\n",
      "|    clip_fraction        | 0.0925     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.01      |\n",
      "|    explained_variance   | 0.268      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.96       |\n",
      "|    n_updates            | 1410       |\n",
      "|    policy_gradient_loss | -0.00188   |\n",
      "|    reward               | 0.97195095 |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 18.5       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 695         |\n",
      "|    ep_rew_mean          | 1.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 222         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006673032 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.02       |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.01        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    reward               | -0.89059776 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 695         |\n",
      "|    ep_rew_mean          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013159458 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.03       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.85        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | 0.000559    |\n",
      "|    reward               | 1.6567634   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 17.4        |\n",
      "-----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 692          |\n",
      "|    ep_rew_mean          | 0.649        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048378357 |\n",
      "|    clip_fraction        | 0.08         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.03        |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.2         |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 0.8758257    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 692        |\n",
      "|    ep_rew_mean          | 0.653      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1311       |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 227        |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00936476 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.04      |\n",
      "|    explained_variance   | 0.208      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 10.5       |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | 0.000197   |\n",
      "|    reward               | -0.6102004 |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 17.8       |\n",
      "----------------------------------------\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 692          |\n",
      "|    ep_rew_mean          | 0.558        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 229          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122500695 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.05        |\n",
      "|    explained_variance   | 0.205        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.94         |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.000711    |\n",
      "|    reward               | -0.9071958   |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 18.2         |\n",
      "------------------------------------------\n",
      "✅ 模型儲存於：E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_5.zip\n"
     ]
    }
   ],
   "source": [
    "# 參數\n",
    "model_dir = \"E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\"\n",
    "indicators = [\"macd\", \"rsi_30\", \"cci_30\", \"wr_14\"]\n",
    "\n",
    "interpolated_df = add_technical_indicators(interpolated_df, indicators=indicators)\n",
    "\n",
    "# 訓練所有模型（每群一個）\n",
    "train_all_models(cluster_labels=cluster_labels, df=interpolated_df, indicators=indicators, model_dir=model_dir)\n",
    "\n",
    "# 測試指定股票（如 1101.TW）\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_by_tic(cluster_labels, test_tic, df, indicators, model_dir, initial_amount=1e6):\n",
    "    from stable_baselines3 import PPO\n",
    "    from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    if test_tic not in cluster_labels:\n",
    "        raise ValueError(f\"{test_tic} not found in cluster_labels.\")\n",
    "\n",
    "    group_id = cluster_labels[test_tic]\n",
    "    model_path = os.path.join(model_dir, f\"ppo_cluster_{group_id}.zip\")\n",
    "    print(f\"📁 Using model for cluster {group_id}: {model_path}\")\n",
    "\n",
    "    group_stocks = [tic for tic, g in cluster_labels.items() if g == group_id]\n",
    "    test_data = df[\n",
    "        (df['date'] >= '2024-01-01') &\n",
    "        (df['date'] <= '2024-10-30') &\n",
    "        (df['tic'].isin(group_stocks))\n",
    "    ].copy()\n",
    "\n",
    "    def make_env():\n",
    "        return create_env_for_stock_np(test_data, stock_tic=group_stocks, indicators=indicators, if_train=False)\n",
    "\n",
    "    vec_env = DummyVecEnv([make_env])\n",
    "    raw_env = vec_env.envs[0]\n",
    "\n",
    "    model = PPO.load(model_path, device=\"auto\")\n",
    "    model.set_env(vec_env)\n",
    "\n",
    "    obs = vec_env.reset()\n",
    "    asset_history = []\n",
    "    date_memory = sorted(test_data['date'].unique())\n",
    "    step = 0\n",
    "\n",
    "    # 為每個股票準備 log list\n",
    "    stock_logs = {tic: [] for tic in group_stocks}\n",
    "\n",
    "    while True:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = vec_env.step(action)\n",
    "\n",
    "        valid_day = max(raw_env.day - 1, 0)\n",
    "        valid_day = min(valid_day, len(raw_env.price_array) - 1)\n",
    "        prices = raw_env.price_array[valid_day]\n",
    "        date = date_memory[valid_day]\n",
    "        total_asset = raw_env.amount + (prices * raw_env.stocks).sum()\n",
    "        asset_history.append(total_asset)\n",
    "\n",
    "        for i, tic in enumerate(group_stocks):\n",
    "            stock_logs[tic].append({\n",
    "                \"date\": date,\n",
    "                \"stock\": tic,\n",
    "                \"price\": prices[i],\n",
    "                \"action\": float(action[0][i]),\n",
    "                \"stock_holding\": float(raw_env.stocks[i]),\n",
    "                \"amount\": float(raw_env.amount),\n",
    "                \"total_asset\": float(total_asset),\n",
    "                \"reward\": float(reward[0]),\n",
    "                \"done\": bool(done[0]),\n",
    "                **{\n",
    "                    f\"indicator_{ind}\": float(raw_env.tech_array[valid_day, j] if raw_env.tech_array.ndim == 2 else raw_env.tech_array[valid_day, i, j])\n",
    "                    for j, ind in enumerate(indicators)\n",
    "                }\n",
    "\n",
    "            })\n",
    "\n",
    "        if done:\n",
    "            print(\"🧪 Final step info:\")\n",
    "            print(f\"  step: {step}\")\n",
    "            print(f\"  amount: {raw_env.amount}\")\n",
    "            print(f\"  price_array: {prices}\")\n",
    "            print(f\"  stocks: {raw_env.stocks}\")\n",
    "            break\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    # ✅ 儲存 log：每支股票一檔 CSV\n",
    "    log_dir = \"E:/python_project/class/Reinforce_Learning/RL/code/log\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    for tic, logs in stock_logs.items():\n",
    "        log_df = pd.DataFrame(logs)\n",
    "        log_path = os.path.join(log_dir, f\"{tic}_log.csv\")\n",
    "        log_df.to_csv(log_path, index=False)\n",
    "        print(f\"📝 Log saved to: {log_path}\")\n",
    "\n",
    "    # 繪圖與績效分析\n",
    "    asset_memory = np.array(asset_history)\n",
    "    date_memory = date_memory[:len(asset_memory)]\n",
    "\n",
    "    if len(asset_memory) >= 2 and asset_memory[-1] < asset_memory[-2] * 0.5:\n",
    "        print(\"⚠️ Final asset drop detected, removing last point.\")\n",
    "        asset_memory = asset_memory[:-1]\n",
    "        date_memory = date_memory[:-1]\n",
    "\n",
    "    final_value = asset_memory[-1]\n",
    "    returns = asset_memory / initial_amount - 1\n",
    "    peak = np.maximum.accumulate(asset_memory)\n",
    "    drawdown = (asset_memory - peak) / peak\n",
    "    max_drawdown = drawdown.min()\n",
    "    daily_returns = np.diff(asset_memory) / asset_memory[:-1]\n",
    "    sharpe_ratio = np.mean(daily_returns) / np.std(daily_returns) * np.sqrt(252) if np.std(daily_returns) > 0 else np.nan\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(date_memory, asset_memory, label=\"Portfolio Value\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Asset Value\")\n",
    "    plt.title(f\"Backtest of cluster {group_id} (target: {test_tic})\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    output_path = f\"E:/python_project/class/Reinforce_Learning/RL/code/result_image/{test_tic}.png\"\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"🖼️ Backtest chart saved to: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"📌 Final Portfolio Value: ${final_value:,.2f}\")\n",
    "    print(f\"📈 Cumulative Return: {returns[-1]*100:.2f}%\")\n",
    "    print(f\"📉 Max Drawdown: {max_drawdown*100:.2f}%\")\n",
    "    print(f\"📊 Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "    print(\"Asset history (tail):\", asset_memory[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "📊 Testing 0050.TW\n",
      "======================\n",
      "📁 Using model for cluster 5: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_5.zip\n",
      "🧪 Final step info:\n",
      "  step: 216\n",
      "  amount: 1000000.0\n",
      "  price_array: [129.63144684  77.88438416  65.64662552  60.69433212]\n",
      "  stocks: [0. 0. 0. 0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\0050.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1301.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1303.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1326.TW_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/0050.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -34.81%\n",
      "📊 Sharpe Ratio: 0.27\n",
      "Asset history (tail): [1502663.194841   1493463.85604208 1505729.283816   1503049.72405495\n",
      " 1000000.        ]\n",
      "\n",
      "======================\n",
      "📊 Testing 1101.TW\n",
      "======================\n",
      "📁 Using model for cluster 2: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_2.zip\n",
      "🧪 Final step info:\n",
      "  step: 216\n",
      "  amount: 1000000.0\n",
      "  price_array: [33.75818634 39.33778191]\n",
      "  stocks: [0. 0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1101.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1102.TW_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/1101.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -7.10%\n",
      "📊 Sharpe Ratio: 0.05\n",
      "Asset history (tail): [1059529.34982137 1065029.34219197 1064029.35745076 1064029.35745076\n",
      " 1000000.        ]\n",
      "\n",
      "======================\n",
      "📊 Testing 1102.TW\n",
      "======================\n",
      "📁 Using model for cluster 2: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_2.zip\n",
      "🧪 Final step info:\n",
      "  step: 216\n",
      "  amount: 1000000.0\n",
      "  price_array: [33.75818634 39.33778191]\n",
      "  stocks: [0. 0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1101.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1102.TW_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/1102.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -6.29%\n",
      "📊 Sharpe Ratio: 0.05\n",
      "Asset history (tail): [1052857.69725835 1058357.68962896 1057357.70488775 1057357.70488775\n",
      " 1000000.        ]\n",
      "\n",
      "======================\n",
      "📊 Testing 1301.TW\n",
      "======================\n",
      "📁 Using model for cluster 5: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_5.zip\n",
      "🧪 Final step info:\n",
      "  step: 216\n",
      "  amount: 1000000.0\n",
      "  price_array: [129.63144684  77.88438416  65.64662552  60.69433212]\n",
      "  stocks: [0. 0. 0. 0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\0050.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1301.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1303.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1326.TW_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/1301.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -33.81%\n",
      "📊 Sharpe Ratio: 0.26\n",
      "Asset history (tail): [1474790.91974736 1465762.07889023 1477800.88022084 1475167.53284271\n",
      " 1000000.        ]\n",
      "\n",
      "======================\n",
      "📊 Testing 1303.TW\n",
      "======================\n",
      "📁 Using model for cluster 5: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_5.zip\n",
      "🧪 Final step info:\n",
      "  step: 216\n",
      "  amount: 1000000.0\n",
      "  price_array: [129.63144684  77.88438416  65.64662552  60.69433212]\n",
      "  stocks: [0. 0. 0. 0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\0050.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1301.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1303.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1326.TW_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/1303.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -34.78%\n",
      "📊 Sharpe Ratio: 0.26\n",
      "Asset history (tail): [1487175.81852989 1478072.08049459 1490211.27640641 1487559.18672981\n",
      " 1000000.        ]\n",
      "\n",
      "======================\n",
      "📊 Testing 1326.TW\n",
      "======================\n",
      "📁 Using model for cluster 5: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_5.zip\n",
      "🧪 Final step info:\n",
      "  step: 216\n",
      "  amount: 1000000.0\n",
      "  price_array: [129.63144684  77.88438416  65.64662552  60.69433212]\n",
      "  stocks: [0. 0. 0. 0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\0050.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1301.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1303.TW_log.csv\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1326.TW_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/1326.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -34.78%\n",
      "📊 Sharpe Ratio: 0.25\n",
      "Asset history (tail): [1462665.60141053 1453711.22979356 1465650.09171678 1463038.41452382\n",
      " 1000000.        ]\n",
      "\n",
      "======================\n",
      "📊 Testing 1402.TW\n",
      "======================\n",
      "📁 Using model for cluster 0: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_0.zip\n",
      "🧪 Final step info:\n",
      "  step: 216\n",
      "  amount: 1000000.0\n",
      "  price_array: [30.23944378]\n",
      "  stocks: [0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1402.TW_log.csv\n",
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/1402.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -8.09%\n",
      "📊 Sharpe Ratio: 0.06\n",
      "Asset history (tail): [1065974.16968245 1067974.17731184 1076474.16205305 1073974.16205305\n",
      " 1000000.        ]\n",
      "\n",
      "======================\n",
      "📊 Testing 1722.TW\n",
      "======================\n",
      "📁 Using model for cluster 3: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_3.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Final step info:\n",
      "  step: 216\n",
      "  amount: 1000000.0\n",
      "  price_array: [65.33745956]\n",
      "  stocks: [0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\1722.TW_log.csv\n",
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/1722.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -10.98%\n",
      "📊 Sharpe Ratio: 0.07\n",
      "Asset history (tail): [ 919163.98661101  917163.97898162  920164.0094992   924163.98661101\n",
      " 1000000.        ]\n",
      "\n",
      "======================\n",
      "📊 Testing 2002.TW\n",
      "======================\n",
      "📁 Using model for cluster 4: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_4.zip\n",
      "🧪 Final step info:\n",
      "  step: 216\n",
      "  amount: 1000000.0\n",
      "  price_array: [26.59179306]\n",
      "  stocks: [0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\2002.TW_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/2002.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -6.39%\n",
      "📊 Sharpe Ratio: 0.04\n",
      "Asset history (tail): [ 956880.84006152  956380.84769092  959380.84006152  961380.84769092\n",
      " 1000000.        ]\n",
      "\n",
      "======================\n",
      "📊 Testing 2301.TW\n",
      "======================\n",
      "📁 Using model for cluster 1: E:\\python_project\\class\\Reinforce_Learning\\RL\\code\\model\\ppo_cluster_1.zip\n",
      "⚠️ Max drawdown triggered, forcing stop.\n",
      "🧪 Final step info:\n",
      "  step: 153\n",
      "  amount: 1000000.0\n",
      "  price_array: [108.83529282]\n",
      "  stocks: [0.]\n",
      "📝 Log saved to: E:/python_project/class/Reinforce_Learning/RL/code/log\\2301.TW_log.csv\n",
      "🖼️ Backtest chart saved to: E:/python_project/class/Reinforce_Learning/RL/code/result_image/2301.TW.png\n",
      "📌 Final Portfolio Value: $1,000,000.00\n",
      "📈 Cumulative Return: 0.00%\n",
      "📉 Max Drawdown: -28.78%\n",
      "📊 Sharpe Ratio: 0.25\n",
      "Asset history (tail): [ 737326.77218733  721424.35263167  721424.35263167  715648.08653761\n",
      " 1000000.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python_project\\class\\class_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\a9706\\AppData\\Local\\Temp\\ipykernel_35252\\359326766.py:118: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "my_stocks = [\"0050.TW\", \"1101.TW\", \"1102.TW\", \"1301.TW\", \"1303.TW\",\n",
    "             \"1326.TW\", \"1402.TW\", \"1722.TW\", \"2002.TW\", \"2301.TW\"]\n",
    "\n",
    "def test_multiple_stocks_by_tic_list(tic_list, cluster_labels, df, indicators, model_dir, initial_amount=1e6):\n",
    "    import traceback\n",
    "\n",
    "    for test_tic in tic_list:\n",
    "        print(f\"\\n======================\")\n",
    "        print(f\"📊 Testing {test_tic}\")\n",
    "        print(f\"======================\")\n",
    "        try:\n",
    "            test_model_by_tic(\n",
    "                cluster_labels=cluster_labels,\n",
    "                test_tic=test_tic,\n",
    "                df=df,\n",
    "                indicators=indicators,\n",
    "                model_dir=model_dir,\n",
    "                initial_amount=initial_amount\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error testing {test_tic}: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "test_multiple_stocks_by_tic_list(\n",
    "    tic_list=my_stocks,\n",
    "    cluster_labels=cluster_labels,\n",
    "    df=interpolated_df,\n",
    "    indicators=indicators,\n",
    "    model_dir=model_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
